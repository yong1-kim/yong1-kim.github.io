---
layout: post
title:  "[Arxiv 2401] Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?"
date:   2024-03-13 22:08:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2401.11911.pdf)  &emsp;

**Hexiang Tan<sup>♠♡</sup>, Fei Sun<sup>♠†</sup>, Wanli Yang<sup>♠♢</sup>, Yuanzhuo Wang<sup>♠</sup>, Qi Cao<sup>♠</sup>, Xueqi Cheng<sup>♠♡</sup>**
<br><sup>♠</sup> CAS Key Laboratory of AI Safety & Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China <sup>♡</sup> University of Chinese Academy of Sciences, Beijing, China <sup>♢</sup> Nankai University, Tianjin, China &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/efe5bdb0-6f48-44eb-b90b-13b14e7ac705)

# Abstract
- (**merging generated context with retrieved context**) Retrieval-augmented generation task 에 대하여, LLM 에 추가적인 정보를 위하여 LLM 스스로 혹은 다른 LLM 이 generated 한 context 를 merging 하려는 시도들이 증가하는데, 이에 대한 연구가 부족하다.
- (**Conflicting dataset**) 저자들은 generated context 와 retrieved context 중 하나에만 golden answer 아 있는 dataset 을 생성하여 reponse 의 origin 을 trace 하는 연구를 제안한다.
- (**Experiment**) 저자들은 실험에서 GPT-4/3.5, LLaMa2 에서 <span style='color:green;font-weight:bold'> generated context 를 favor 하는 significant bias </span> 를 발견한다. 또한, LLM-generated context 가 query 에 대해서는 훨씬 높은 relevancy 를 가지는 것을 발견한다.
- (**Takeaway**) LLM 이 diverse context 를 어떻게 merge 하는지 이해하며, 현재의 RALM 에 대한 진보에 기여할 수 있다.

## 1. Introduction
<span style='color:green;font-weight:bold'> ▶ Using Auxiliary info in LLMs </span>
<br>
최근 Knowledge-intensive task 에서 LLM 에 auxiliary information 을 활용하여 성능을 끌어올리는 연구들이 많이 존재한다. ([[1]](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00605/118118/In-Context-Retrieval-Augmented-Language-Models))
최근 여러 연구에서 Retrieval-augmented approach 를 대신하여, LLM 이 생성한 context 를 활용하는 generation-augmented apporach([[2]](https://aclanthology.org/2022.acl-long.225.pdf),[[3]](https://arxiv.org/pdf/2210.01296.pdf)) 를 차용한다.
대표적인 예시로, [GENREAD](https://arxiv.org/abs/2209.10063) 가 있다.

<span style='color:green;font-weight:bold'> ▶ Hybrid Approach </span>
<br>
최근 연구들([[4]](https://arxiv.org/abs/2209.10063),[[5]](https://aclanthology.org/2023.acl-long.546/)) 에서는 Retrieved context information 과 generated context information 을 합쳐서 넣는 hybrid approach 에 대한 방법론이 제시되고 있다.
그러나 이 hybrid approach 에는 significnat challenge 가 존재하는데, <span style='background-color: #ffdce0'> diverse source 의 conflict 가 information integration 의 effectiveness 를 impede 한다([[7]](https://aclanthology.org/2023.emnlp-main.286/))</span>는 것이다.
이 연구에서는 LLM 이 이 generated-retreived context 사이 conflict 를 어떻게 resolve 하는지를 탐구한다.

<span style='color:green;font-weight:bold'> ▶ How LLMs handle conflict between retrieved info and generated info </span>
<br>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/35150b62-1d7b-4e4d-8b56-abcf139bf121)

저자들은 특별한 케이스에 대하여, hybrid approach 가 위의 그림처럼 실패하는 것을 보인다.
이 이유를 탐구하기 위해, <span style='background-color: #dcffe4'> LLM 이 merging 하는 과정을 나눠서 분석하는 systematic framework 을 제시한다. </span>
저자들은 generated and retrived context 중 하나에만 정답이 있는 conflicting dataset 을 의도적으로 생성한 뒤, LLM 이 어떤 context 를 고르는지를 탐구한다.

<span style='background-color: #dcffe4'> 
여러 실험 결과, GPT-4/3.5, LLaMa2 같은 SOTA LLM 들에서 generated context 를 favor 하는 siginficant bias 를 발견한다. </span>
추가적으로, 이 genreated context 가 LLM 스스로 만든 것이든, 다른 LLM 이 만든 것이든 상관없이(regardless) 같은 결과가 나온다는 것이다.
따라서, LLM 들이 parameter knowledge 와 external information 사이의 conflict 가 있을 때, 어떻게 merging 하여 사용할 것인가에 대해 critical challenge 가 있음을 보인다.
<span style='background-color: #dcffe4'> 이 과정에서 confirmation bias 가 아닌 text similiarity 가 LLM 이 context 를 선정하는 key factor 임을 보인다.
 </span> 

## 2. Background & Study Formulation
# 2.1 Background
Retrieval approach, generation-augmented approach, 그리고 hybrid approach 에 대한 도식은 아래와 같다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/ef36d6b0-8bf7-417c-938b-1c67fc630076)
  

# 2.2 Answer Tracing Task

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/f78e5d93-f36a-4902-a203-7d0b1134a5b8)

저자들은 answer 가 generated context 와 retrieved context 중 어떠한 것에서 비롯되는지를 탐구하는 answer tracing task 를 제안한다.
Task 를 풀 때는 LLM zero-shot setting 을 활용한다.

## 3. Experimental Setup
# 3.1 Context-Conflicting Datasets

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/8d684c80-a1d2-42d8-836f-a0684306fde7)

실험을 위해, retrieved context 와 generated context 사이에 정답이 하나만 존재하는 context-conflicting dataset 을 만든다.
그 생성 criteria 는 **Traceability** (ANSWER는 반드시 어떠한 context 에 support 된다) 와 **Exclusitvity** (ANSWER 는 반드시 둘 중 하나의 context 에만 support 된다) 이다.

데이터 생성에는 NaturalQuestion (NQ) 와 TriviaQA 의 golden answer 를 활용하였다.

<span style='color:green;font-weight:bold'> Step 1. Context Preparation </span>
<br>
Retriever 로는 [Contriever](https://arxiv.org/abs/2112.09118) 의 top-1 ranked passage 를 활용한다. 참고로 Contriever 는 최근 RALM 에도 사용되는 명실 상부 강력한 off-the-shelf retriever 중 하나이다.

Generator 로는 GENREAD framework 을 따라 LLM 을 활용한다. 재현성을 위해 temperature 는 0 으로 한다. 대부분 Retriver 가 100 work 정도 context 를 가져오는데 반해, generator 는 250 word 가 넘게 길게 생성하는데, <span style='background-color: #dcffe4'> 이 length discrepancy 도 하나의 potential effect 일 수 있으므로 3% 정도의 discrepancy 가 되게 length constraint 를 부여한다. </span>

<span style='color:green;font-weight:bold'> Step 2. Sample Flitering </span>
<br>
Traceability 를 확보하기 위한 filtering 과정을 거친다.
즉, ANSWER 가 Retrieved context 와 Generated Context 중 하나에라도 support 되는 것만 남기고 버려진다. ANSWER 가 둘 중 하나라도 support 되지 않고, intrinsic parameter knowledge 에 의존하는 경우는 버리는 것이다.

<span style='color:green;font-weight:bold'> Step 3. Building Dataset </span>
<br>
Exculsivity 를 확보하기 위해 ANSWSER 가 only one context 에 의존하는 case 만 남기고 filtering 한다.
이 떄, Retrieved context 에 의존하는 경우를 *AIR* 로, Generated context 에 의존하는 경우를 *AIG* 로 명명한다.

# 3.2 Statistics of Datasets

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/a3d3a3e4-7926-4d64-9d11-a5ca3ca27a56)

Generator 와 Reader 로 활용된 LLM 모델에 따른 statitsics 는 위의 표와 같다.
NQ 와 TriviaQA 의 10% 정도 내외의 작은 portion 만이 해당되는 것을 볼 수 있다.
**GPT-4 는 conflicting instance 의 양이 적은데, 이는 retrieved or generated context 를 활용하는 능력이 뛰어나기 때문이라고 해석한다**

# 3.3 Evaluation Metric

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fa5f41e1-af48-4b0f-812a-09657ce1556a)

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/a4e156be-02d1-46da-8e30-6693d95c5b0f)

DiffGR 이라는 [-1,1] scale 의 metric 을 제안한다.
AIR 케이스, 즉 answer 가 retrieved context 에서 온 경우에 대하여, Ideal LLM 의 DiffGR 값은 -1 이 될 것이다.

## 4. How LLMs Merge Contexts?
# 4.1 LLMs Prefer Self-Generated Contexts
<span style='color:green;font-weight:bold'> EM Results </span>
<br>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/6f5a6e25-f94e-4f15-886d-8b7603f7b0f5)

- <span style='background-color: #dcffe4'> LLM 이 AIR 데이터셋에 매우 낮은 성능을 보이면서 AIG 에서는 매우 높은 성능을 보여 generated context 에 매우 크게 의존함을 알 수 있다. </span>

<span style='color:green;font-weight:bold'> DiffGR Results </span>
<br>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/0b9c98cb-ca61-4ecc-8031-e5ca8f892150)

- <span style='background-color: #dcffe4'> Ideal LLM 이라면  AIG 의 경우 1, AIR 의 경우 -1이 나와야 하는데, 위의 그래프에서 AIR 도 양수가 나오기 때문에, AIR 을 잘 못하고 Generated context 에 크게 의존함을 알 수 있다. </span>


# 4.2 LLMs Broadly Prefer Generated Contexts

4.1 의 결과는 LLM 이 스스로 만든 self-generated context 를 선호하는 경향성을 확인시킨다. 그렇다면 다른 LLM 이 만든 generated context 에도 의존할까?

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/acbdc40a-124c-4276-91e3-cac5050b49bd)

- <span style='background-color: #dcffe4'> ) LLMs also biased towards contexts
generated by other LLMs. </span>
- <span style='background-color: #dcffe4'> )LLMs usually exhibit a stronger bias to contexts generated by themselves.  </span>


## 5. Why LLMs Prefer Generated Contexts
# 5.1 Effect of Confirmation Bias
# 5.2 Effect of Text Similarity
# 5.3 Effect of Context Completeness

## Conclusion & Future Work

## Limitation




<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
