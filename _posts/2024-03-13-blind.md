---
layout: post
title:  "[Arxiv 2401] Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?"
date:   2024-03-13 22:08:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2401.11911.pdf)  &emsp;

**Hexiang Tan<sup>♠♡</sup>, Fei Sun<sup>♠†</sup>, Wanli Yang<sup>♠♢</sup>, Yuanzhuo Wang<sup>♠</sup>, Qi Cao<sup>♠</sup>, Xueqi Cheng<sup>♠♡</sup>**
<br><sup>♠</sup> CAS Key Laboratory of AI Safety & Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China <sup>♡</sup> University of Chinese Academy of Sciences, Beijing, China <sup>♢</sup> Nankai University, Tianjin, China &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/efe5bdb0-6f48-44eb-b90b-13b14e7ac705)

# Abstract
- (**merging generated context with retrieved context**) Retrieval-augmented generation task 에 대하여, LLM 에 추가적인 정보를 위하여 LLM 스스로 혹은 다른 LLM 이 generated 한 context 를 merging 하려는 시도들이 증가하는데, 이에 대한 연구가 부족하다.
- (**Conflicting dataset**) 저자들은 generated context 와 retrieved context 중 하나에만 golden answer 아 있는 dataset 을 생성하여 reponse 의 origin 을 trace 하는 연구를 제안한다.
- (**Experiment**) 저자들은 실험에서 GPT-4/3.5, LLaMa2 에서 <span style='color:green;font-weight:bold'> generated context 를 favor 하는 significant bias </span> 를 발견한다. 또한, LLM-generated context 가 query 에 대해서는 훨씬 높은 relevancy 를 가지는 것을 발견한다.
- (**Takeaway**) LLM 이 diverse context 를 어떻게 merge 하는지 이해하며, 현재의 RALM 에 대한 진보에 기여할 수 있다.

## 1. Introduction
<span style='color:green;font-weight:bold'> ▶ Using Auxiliary info in LLMs </span>
<br>
최근 Knowledge-intensive task 에서 LLM 에 auxiliary information 을 활용하여 성능을 끌어올리는 연구들이 많이 존재한다. ([[1]](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00605/118118/In-Context-Retrieval-Augmented-Language-Models))
최근 여러 연구에서 Retrieval-augmented approach 를 대신하여, LLM 이 생성한 context 를 활용하는 generation-augmented apporach([[2]](https://aclanthology.org/2022.acl-long.225.pdf),[[3]](https://arxiv.org/pdf/2210.01296.pdf)) 를 차용한다.
대표적인 예시로, [GENREAD](https://arxiv.org/abs/2209.10063) 가 있다.

<span style='color:green;font-weight:bold'> ▶ Hybrid Approach </span>
<br>
최근 연구들([[4]](https://arxiv.org/abs/2209.10063),[[5]](https://aclanthology.org/2023.acl-long.546/)) 에서는 Retrieved context information 과 generated context information 을 합쳐서 넣는 hybrid approach 에 대한 방법론이 제시되고 있다.
그러나 이 hybrid approach 에는 significnat challenge 가 존재하는데, <span style='background-color: #ffdce0'> diverse source 의 conflict 가 information integration 의 effectiveness 를 impede 한다([[7]](https://aclanthology.org/2023.emnlp-main.286/))</span>는 것이다.
이 연구에서는 LLM 이 이 generated-retreived context 사이 conflict 를 어떻게 resolve 하는지를 탐구한다.

<span style='color:green;font-weight:bold'> ▶ How LLMs handle conflict between retrieved info and generated info </span>
<br>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/35150b62-1d7b-4e4d-8b56-abcf139bf121)

저자들은 특별한 케이스에 대하여, hybrid approach 가 위의 그림처럼 실패하는 것을 보인다.
이 이유를 탐구하기 위해, <span style='background-color: #dcffe4'> LLM 이 merging 하는 과정을 나눠서 분석하는 systematic framework 을 제시한다. </span>
저자들은 generated and retrived context 중 하나에만 정답이 있는 conflicting dataset 을 의도적으로 생성한 뒤, LLM 이 어떤 context 를 고르는지를 탐구한다.

<span style='background-color: #dcffe4'> 
여러 실험 결과, GPT-4/3.5, LLaMa2 같은 SOTA LLM 들에서 generated context 를 favor 하는 siginficant bias 를 발견한다. </span>
추가적으로, 이 genreated context 가 LLM 스스로 만든 것이든, 다른 LLM 이 만든 것이든 상관없이(regardless) 같은 결과가 나온다는 것이다.
따라서, LLM 들이 parameter knowledge 와 external information 사이의 conflict 가 있을 때, 어떻게 merging 하여 사용할 것인가에 대해 critical challenge 가 있음을 보인다.
<span style='background-color: #dcffe4'> 이 과정에서 confirmation bias 가 아닌 text similiarity 가 LLM 이 context 를 선정하는 key factor 임을 보인다.
 </span>
 
 

## 2. Background & Study Formulation
# 2.1 Background
# 2.2 Answer Tracing Task

## 3. Experimental Setup
# 3.1 Context-Conflicting Datasets
# 3.2 Statistics of Datasets
# 3.3 Evaluation Metric

## 4. How LLMs Merge Contexts?
# 4.1 LLMs Prefer Self-Generated Contexts
# 4.2 LLMs Broadly Prefer Generated Contexts

## 5. Why LLMs Prefer Generated Contexts
# 5.1 Effect of Confirmation Bias
# 5.2 Effect of Text Similarity
# 5.3 Effect of Context Completeness

## Conclusion & Future Work

## Limitation




<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
