---
layout: post
title:  "[Arxiv 2312] NoMIRACL: Knowing When You Don’t Know for Robust Multilingual Retrieval-Augmented Generation"
date:   2024-02-02 12:00:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2312.11361.pdf) &emsp;
[[github]](https://github.com/project-miracl/nomiracl?tab=readme-ov-file) &emsp;
[[huggingface]](https://huggingface.co/datasets/miracl/nomiracl) 

**Nandan Thakur<sup>1</sup>, Luiz Bonifacio<sup>1,3</sup>, Xinyu Zhang<sup>1</sup>, Odunayo Ogundepo<sup>1</sup>, Ehsan Kamalloo<sup>1</sup>, David Alfonso-Hermelo<sup>2</sup>, Xiaoguang Li<sup>2</sup>, Qun Liu<sup>2</sup>, Boxing Chen<sup>2</sup>, Mehdi Rezagholizadeh<sup>2</sup>, Jimmy Lin<sup>1</sup>**
<br><sup>1</sup> David R. Cheriton School of Computer Science, University of Waterloo, Canada <sup>2</sup> Huawei Noah’s Ark Lab <sup>3</sup> FEEC-Unicamp, Brazil &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fff51e5d-5e5c-439e-a638-864582cf36ab)

## Abstract
- (**Lack of Evaluation of Multilingual LLM robustness**) RAG 가 LLM external knowledge 에 를 leverage 하여 factual hallucination 을 경감하는데 큰 역할을 하지만, external retreived knowledge 속의 error 에 대한 robustness 에 대한 평가, 특히 영어 이외의 다른 언어 집단에서의 평가는 어렵다.
- (<span style='color:green;font-weight:bold'> NoMARICL </span>) 18개의 언어에 대하여, RAG 에 대한 LLM robustness 를 측정하는 NoMIRACL benchmark 를 제안한다. 이는 인간이 평가한 No-relevant passage 를 의도적으로 query 로 집어넣어 평가를 한다.
- (**LLM Robustness**) 논문에서는 두 가지 측면에서 RAG 에 대한 LLM robustness 를 측정하는데 (1) *hallucination rate* 와 (2) *error rate* 이다.
- (Experiment) GPT-4 가 영어나 프랑스 등의 higher-resource language 에서 더 hallucination 을 잘 일으키는 현상을 발견한다. 앞으로 non-relevant information 을 어떻게 잘 reject 하는 지에 대한 foundation 연구가 될 수 있다고 주장한다.


## 1. Introduction




<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
