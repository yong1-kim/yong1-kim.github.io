---
layout: post
title:  "[Arxiv 2312] NoMIRACL: Knowing When You Don’t Know for Robust Multilingual Retrieval-Augmented Generation"
date:   2024-02-02 12:00:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2312.11361.pdf) &emsp;
[[github]](https://github.com/project-miracl/nomiracl?tab=readme-ov-file) &emsp;
[[huggingface]](https://huggingface.co/datasets/miracl/nomiracl) 

**Nandan Thakur<sup>1</sup>, Luiz Bonifacio<sup>1,3</sup>, Xinyu Zhang<sup>1</sup>, Odunayo Ogundepo<sup>1</sup>, Ehsan Kamalloo<sup>1</sup>, David Alfonso-Hermelo<sup>2</sup>, Xiaoguang Li<sup>2</sup>, Qun Liu<sup>2</sup>, Boxing Chen<sup>2</sup>, Mehdi Rezagholizadeh<sup>2</sup>, Jimmy Lin<sup>1</sup>**
<br><sup>1</sup> David R. Cheriton School of Computer Science, University of Waterloo, Canada <sup>2</sup> Huawei Noah’s Ark Lab <sup>3</sup> FEEC-Unicamp, Brazil &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fff51e5d-5e5c-439e-a638-864582cf36ab)

## Abstract
- (**Lack of Evaluation of Multilingual LLM robustness**) RAG 가 LLM external knowledge 에 를 leverage 하여 factual hallucination 을 경감하는데 큰 역할을 하지만, external retreived knowledge 속의 error 에 대한 robustness 에 대한 평가, 특히 영어 이외의 다른 언어 집단에서의 평가는 어렵다.
- (<span style='color:green;font-weight:bold'> NoMARICL </span>) 18개의 언어에 대하여, RAG 에 대한 LLM robustness 를 측정하는 NoMIRACL benchmark 를 제안한다. 이는 인간이 평가한 No-relevant passage 를 의도적으로 query 로 집어넣어 평가를 한다.
- (**LLM Robustness**) 논문에서는 두 가지 측면에서 RAG 에 대한 LLM robustness 를 측정하는데 (1) *hallucination rate* 와 (2) *error rate* 이다.
- (Experiment) GPT-4 가 영어나 프랑스 등의 higher-resource language 에서 더 hallucination 을 잘 일으키는 현상을 발견한다. 앞으로 non-relevant information 을 어떻게 잘 reject 하는 지에 대한 foundation 연구가 될 수 있다고 주장한다.


## 1. Introduction
![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/8ed37ae8-a283-43c0-954c-a8e6a9febeea)
<span style='color:green;font-weight:bold'> ▶ Challenging issue in RAG </span>
<br>
Retrieval Augmented Generation (RAG) 는 reliable knowledge corpora 속의 정보를 LLM 에 잘 주입시키는 역할을 한다.
그러나 RAG 는 LLM 을 통한 강력한 generation 단에 비하여, retrieval system 은 relevant information 을 가져오는데 있어서 어려움을 보이는 경우가 있다.
<span style='background-color: #dcffe4'> 특히, zero-shot domain 이나 low-resource language 에 대해서는 이런 retrieval 취약점이 더 잘 드러난다. </span>
이러한 incorrect 하거나 non-relevant 한 information 은 LLM 으로 하여금 hallucination 을 일으키게 만든다.
하지만, 현재까지 low-resource 등 multilingual setting 에서 LLM reasoning capa 를 측정한 연구는 없었다.

<span style='color:green;font-weight:bold'> ▶ NoMIRACL </span>
<br>
이 논문에서는 first-stage external information 에서의 error 에 저항하는 LLM robustness 를 측정하는 **NoMIRACL** benchmark 를 소개한다.
30 명의 native speaker 를 고용하여 dataset 을 구성하였다.
NoMIRACL 은 두 개의 subset 으로 구성되어있으며, 각각 non-relevant, relevant 이다.

GPT-4 를 baseline 으로 하여 실험한 결과, GPT-4 가 non-relevant passage 에 대해 33.2% hallucination rate 을 보이는 것을 관찰하였고, relevant subset 에 대해서는 14.2% 의 비교적 낮은 error rate 을 보이는 것을 관찰하였다.
이를 통해 RAG 에서의 retrieval 단의 중요성을 확인할 수 있다.

추가적으로, GPT-4 hallucination rate 과 language resource size 에 positive correlation 이 있음을 통해, higher-resource (영어, 프랑스어등) 에서 더 많은 hallucination 이 있음을 관찰한다.

## 2. Background and Problem Identification

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/4d674f1c-2fb9-4f24-9d78-fa30b3482797)




<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
