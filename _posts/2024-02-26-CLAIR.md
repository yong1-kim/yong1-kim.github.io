---
layout: post
title:  "[EMNLP2023] CLAIR: Evaluating Image Captions with Large Language Models"
date:   2024-02-26 17:00:00 +0900
use_math: true
categories: [Vision-and-Language, LLM, PLM]
---

[[pdf]](https://aclanthology.org/2023.emnlp-main.841v2.pdf) &emsp;
[[github]](https://davidmchan.github.io/clair/)

**David M. Chan, Suzanne Petryk, Joseph E. Gonzalez, Trevor Darrell, John Canny**
<br> University of California, Berkeley &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/ae8bbd04-baed-4689-b435-9e142546d4e0)

## Abstract
- (**Image CaptioningMetric**) Image caption model 을 평가하는 metric 은 semantic relevance, visual structure, object interactions, caption diversity, specificity 등의 요소를 고려해야 한다.
- (<span style='color:green;font-weight:bold'> CLAIR </span>) 본 논문에서는 Large Language Model (LLM)의 zero-shot capability 를 leverage 하여 새로운 image captioning metric 을 제시한다.
- (**Experiment**) CLAIR 는 높은 human correlation 을 보이는데, SPICE 보다 39.6%, RefCLIP-S 보다 18.3% 높은 human correlation 을 보인다.

## 1. Introduction & Background
<span style='color:green;font-weight:bold'> ▶ Image Captioning Metric </span>
<br>
Image caption model 을 평가하는 metric 은 semantic relevance, visual structure, object interactions, caption diversity, specificity 등의 요소를 고려해야 하므로 challenging 하다.
기존에 n-gram 기반의 metric 들인 BLEU, CIDEr, SPICE 등이 제시되었고, 이후 모델을 기반으로 한 CLIPSCore, TIFA, SeeTrue, VPEval, 이환희 박사님의 연구인 UMIC 나 내 연구인 PR-MCS 등도 제시되었다.
<span style='background-color: #ffdce0'> 그러나 기존의 metric 들은 낮은 human correlation 을 보이거나, 혹은 너무 costly 하여 metric 으로 활용하기 어려운 점이 있었다. </span>

<span style='color:green;font-weight:bold'>  ▶ CLAIR </span>
<br>
최근 Large Language Model (LLM) 이 등장하면서, 매우 강력한 성능을 보인다.
이 연구에서는 이 LLM 의 강력한 "judge" 능력을 leverage 하여 <span style='background-color: #dcffe4'> CLAIR(Criterion using LAnguage models for Image caption Rating) </span> 을 제안한다.
이는 단순하게 LLM 으로 하여금 caption 들에 대한 numeric rating 을 생성하게 한다.
저자들은 _semantic text quality_ 를 LLM 에게 직접적으로 측정하게 하는 최초의 연구라고 주장한다.

MS-COCO, Flickr8k, PASCAL-50S 등의 대표적인 image captioning metric 들에 대한 실험 결과, CLAIR 가 아주 놀라울 정도로 강력한 human correlation 을 보인다.
또한, <span style='background-color: #dcffe4'> CLIAR_E </span> 라는 Ensemble 모델이 더 높은 성능을 가진 metric 임을 실험적으로 보인다.
이 논문이 가지는 contribution 을 아래와 같다.

- (1) Language-only model 로 vision-language task 를 평가할 수 있는 metric 을 제시한 점.
- (2) LLM 이 단순 scalar rating 을 잘하는 것을 넘어, reasoning 을 기반으로 rating 을 할 수 있다는 점.
- (3) LLM 이 image caption 을 평가하기 위한 여러 기준(criteria) 들에 대해서 대부분 다 반영할 수 있다는 것을 보인 점.

## 2. CLAIR: LLMs for Caption Evaluation

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/958f0f08-1692-4342-82d0-94764abfe8eb)

<span style='background-color: #dcffe4'> CLAIR 는 Image Captioning Metric 을 위해 text-only model 인 LLM 을 사용하기 때문에, human-readable text completion task 로의 전환을 시도한다.
 </span>
 위의 Figure 에 나와있는 Prompt 를 이용하여 text completion task 로 score 를 내뱉게 하며, temperature 를 0 으로 하여 (greedy) 재현성(reproductability)를 확보한다.
 그리고 재현성을 위해, API 의 default inference parameter 에 zero-shot 으로 실험을 진행한다.

 Backbone model 로는 GPT-3.5 (ChatGPT), Claude, PaLM 을 사용하고, Koala, Vicuna 와 같은 open-source model 을 사용하여 보았지만 이 open-source model 은 매우 나쁜 human correlation 을 보였다고 한다.
 Baseline metric 으로는 BLEU, ROUGE, METEOR, CIDEr 그리고 CLIP-Score 를 비교한다.

## 3.  Evaluation & Discussion

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/3d3a5d36-450b-481e-9a0d-533eea437366)

# 3.1. Sample-level human correlation

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/0799c752-c4c3-43d5-8cc3-ff1bad876378)

# 3.2. System-level human correlation

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fc5ccd12-51d1-48b5-a9de-c087d3f3a5f8)


# 3.3 Decision making

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/540340a5-3389-4614-a4c3-587e92f10162)


# 3.4. Groups of Captions

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/a4e9db1f-8aed-4104-977b-fdc97739075e)


## 4. Limitations

## Conclusion


<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
