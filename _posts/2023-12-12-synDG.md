---
layout: post
title:  "[ACL2023] A Synthetic Data Generation Framework for Grounded Dialogues"
date:   2023-12-12 21:00:00 +0900
use_math: true
categories: [Dialogue, PLM]
---

[[pdf]](https://aclanthology.org/2023.acl-long.608v2.pdf) &emsp;

**Jianzhu Bao<sup>1,5</sup>, Rui Wang<sup>1,6</sup>, Yasheng Wang<sup>3</sup>, Aixin Sun<sup>2</sup>, Yitong Li<sup>3,4</sup>, Fei Mi<sup>3</sup>, Ruifeng Xu<sup>1,5,6</sup>**
<br><sup>1</sup> Harbin Institute of Technology, Shenzhen, China <sup>2</sup> Nanyang Technological University, Singapore <sup>3</sup> Huawei Noah’s Ark Lab, Huawei Technologies Co., Ltd. <sup>4</sup> Peng Cheng Laboratory, Shenzhen, China <sup>5</sup> Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies
 &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/478020be-925e-4d43-bcc9-d032a09fc3e3)

# Abstract
- (Motivation) 여타 다른 Dialogue 와 마찬가지로, <span style='background-color: #dcffe4'> grounded-dialog </span>를 generation 하는 것은 매우 costly 하다.
- (**SynDG**) Wikipedia, persona profile 등의 freely available knowledge data 와 pre-trained Language model 을 활용하는 synthetic data generation framework 인 <span style='background-color: #dcffe4'> synDG </span>를 제안한다.
- (**Dialog FLOW**) SynDG 의 key idea 는 Dialog flow 를 통해 coherence 를 유지하는 것이다.
- (Two-level filtering strategy) Synthetic dialog 와 dialog flow 의 coherence 를 위하여 two-level filtering (flow-level and utterance-level) strategy 를 제안한다.
- (Experiment) Full training data 와 low-resource scenario 에서 model performance 를 boost 한다.

# Introduction
이 연구에서는 **Grounded dialog system** 을 다루는데, 이는 knowledge 에 relevant 하고 informative 한 reponse 를 제공하는 대화이다. 
다른 여타 dialog 와 마찬가지로 grounded dialog 역시 데이터셋 부족 문제가 있다.
기존의 다른 방법들 ([RL 을 활용](https://aclanthology.org/2022.sigdial-1.3/)하거나, [user simulation 을 활용](https://aclanthology.org/2022.sigdial-1.21/)) 등이 제안되었지만, 이들은 **Dialog flow** 를 반영하지 않는다.

<span style='background-color: #dcffe4'> Dialog Flow 는 dialogue 의 outline 이라고 할 수 있다. </span> 
Dialog flow 에는 각 session 에서의 content 와 trajectory (topic shift 등) 이 담길 수 있다.
위의 그림에서와 같이, _"husky"_ 에서 _"sled dogs"_ 로, 그리고 다시 _"huskies as pets"_ 로 자연스럽게, dialog 가 흐르는 것을 알 수 있는데, 만약, _"Esquimaux"_ 와 같이, husky 와 같은 wikipedia page 에 등장하지만 다른 knowledge peice 로 대체하면 flow 가 inconsistent 해진다. 
따라서 가장 중요한 것은 dialog flow 을 정교하게 설계하여, coherence 와 smoothness 를 확보하는 것이다.

이에 이 연구에서는 **Syn**thetic **D**ialog **G**eneration (**SynDG**) 를 제안한다.
<span style='background-color: #dcffe4'> 이렇게 생성된 dilaog 는 auxiliary training data 로써 활용될 수 있다. </span>
SynDG 는 **Heuristic** 을 통해 Wikipeida 와 persona knowledge 로 부터 dialog flow 를 만들고, T5 를 이용해 generation 을 진행한다.
이후, Flow-level, Utterance-level 의 two-level filtering 을 통해 quality assurance 를 진행한다.
이후 실험에서, 생성된 두 데이터셋을 additional training dataset 으로 활용하였을 때, 더 좋은 성능을 보여주었다.

# Task Formulation

Training Grounded Dialog $D^t = (C^t_i,K^t_i,r^t_i )^{N_t}_{i=1}$ 에 대해, $C$ 는 dialog context, $K$ 는 knowledge, $r$은 response 일 때, $D$로 부터 $P(r|C,K)$ 를 학습하는 것이 목표이다. 
이후 이를 통해, synthetic data $D^s$ 생성 후, $\{D^t U D^s \}$ 를 통해 generation model 이 나아지는지 확인한다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/c7fcbe86-08cb-4a00-8da7-4ca413b756cd)

# Methodology
위의 그림은 SynDG 의 전체적인 Framework 구조이다. 
세 가지로 이뤄져 있는데, (1) task-specific heuristic 을 통한 dialog flow 생성, (2) dialog flow 을 바탕으로 utterance realization (3) two-level filtering 을 통한 quality 확보이다.

<span style='color:green;font-weight:bold'> 1. Dialogue Flow Construction </span>
<br>
Dialog FLow $F=\{f_1,f_2,...,f_n_f\}$ 는 각각 knowledge piece $f$ 들로 이루어진다.
각각 knowedge piece $f$ 는 Knowledge base $K$ 의 하나의 piece 거나, 여러 piece 들의 연속이거나, "[none]" 이 되어 knowledge 가 없을 수 있다.
<span style='background-color: #dcffe4'> 각각 하나의 knowledge piece 가 utterance 가 되며, 홀수 번째는 첫 번째 speaker, 짝수 번째는 두 번째 speaker 의 utterance 가 된다. </span>
학습과정에서는, 각각의 utterance 마다 knowledge piece 가 있으므로 손쉽게 flow $f$를 얻을 수 있다.
**중요한 것은 Inference 단계에서, dialog flow 를 확보하는 방법이다.**
논문에서는, heuristic 을 이용한다.
PersonaChat 에 대해서는 persona utterance 들을 모아 Knowledge Base $\K$로 만든 후, 이 중 zero, one, or more persona sentence 각각을 $f$로 활용한다.
WoW (Wizard of Wikipedia) 에 대해서는, chosen passage 와 첫 번째 turn 에서 retrieve 되는 passage 를 knowledge corpus $\K$ 로 한 뒤, 각각의 turn 에서 최소 한 개의 $f$ 를 추출해서 사용한다.

<span style='background-color: #dcffe4'> Heuristic 을 활용한 방법이 universally applicable 하지 않다는 것을 저자들도 인지하지만, minor modification 을 통해 모든 데이터셋에 적용가능하다고 주장하고 있다. </span>

<span style='color:green;font-weight:bold'> 2.  Dialogue Content Realization </span>
<br>
Dialog flow 를 통해 utterance 를 생성하도록 T5 를 Finetuning 한다
$u_i$ 를 생성하기 위하여 $(u_1, u_2, ..., u_{t-1},[t],f_i,[/t],f_{i+1},...,f_{i+m})$ 을 input 으로 한다. $[t]$ 와 $[/t]$ 는 $u_i$ 가 $f_i$로 부터 생성됨을 강조한다.
Practically,_ [user]_ 와 _[agent]_ special token 을 추가한다.


<span style='color:green;font-weight:bold'> 3. Two-level Filtering </span>
<br>
T5 의 text-infilling task (masked sentence modeling) 을 통해 filter 를 학습한다. 마치 Dialog Reconstruction 와 마찬가지로, Training dataset 에서 utterance 와 flow 를 mask 하고 T5 기반 filter 가 맞추는 방식으로 학습을 한뒤, Inference 단계에서는 filter 가 내놓는 log prob 을 score 로 활용한다.
이 방식을 utterance 와 flow 에서 모두 적용한 뒤 합하여 최종 score 로 활용한다.

# Experiment
[Dataset]


