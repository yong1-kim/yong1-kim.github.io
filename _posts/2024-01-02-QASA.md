---
layout: post
title:  "[ICML2023] QASA: Advanced Questino Answering on Scientific Articles"
date:   2024-01-02 09:18:00 +0900
use_math: true
categories: [LLM]
---

[[pdf]](https://proceedings.mlr.press/v202/lee23n/lee23n.pdf)
[[github]](https://github.com/lgresearch/QASA)

**Yoonjoo Lee <sup>1*</sup>, Kyungjae Lee <sup>2*</sup>, Sunghyun Park <sup>2</sup>, Dasol Hwang <sup>2</sup>, Jaehyeon Kim <sup>2</sup>, Hong-in Lee <sup>3</sup>, Moontae Lee <sup>2,4</sup>**
<br><sup>1</sup> KAIST (Work done at LG AI Research) <sup>2</sup> LG AI Research <sup>3</sup> Yonsei University <sup>4</sup> University of Illinois Chicago. Correspondence to: Moontae Lee <moontae.lee@lgresearch.ai>.

 &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/302e9e4a-091a-48b0-8f75-4be57475fd9d)

# Abstract
- (Motivation) Intellectual thinking 의 필수불가결한 요소인 Reasoning 에 대해, Question Answering (QA) 이 하나의 방법일 수 있다. 그러나 현재 대부분의 QA 는 deeper understanding 없이 shallow QA 를 풀거나 짧은 factoid 를 푸는데 그친다.
- (Associative Thinking) 복수의 연구에서, 인간은 연합 사고 (associative thinking) 를 통해 관련 지식의 조각들을 모은 후, grounding 한다.
- (QASA) 저자들은 세 타입 : surface, testing, deep question 으로 구성된, <span style='color:green;font-weight:bold'> AI/ML field scentific article 에 대한 1,798 개의 full stack reasoning dataset 인 QASA </span>  를 제안한다.
- (Experimental Results) QASA 를 활용하여 LLM 을 학습시켰을 때, InstructGPT 를 big margin 으로 outperform 한다.

# Introduction 

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/20e0349a-cb2d-4fb9-94cc-cd7282d6382e)


1974년 부터 이어진 인지과학 [연구](https://www.sciencedirect.com/science/article/pii/0010027774900171)에서, 인간은 Dual process 로 
reasoning 을 진행한다는 연구가 있었다. 첫 Step 은 연합 사고(associative thinking) 이고, 다음 step 은 logical reasoning 이다.
QA 의 context 로 본다면, 첫 번째는 lexical matching 등을 통한 knowledge piece 를 모으는 것이고, 두 번째는 답변을 하기 위한 evidential retionale 을 찾는 과정일 것이다.

Reading Comprehension (RC) 은 다양한 QA 를 형상화한 하나의 reasoning task 이다.
SQuAD, NewsQA, DROP, Natural Questions 등의 task 가 제안되었다.
이러한 것들이 모델의 성능을 많이 발전시키는데 큰 역할을 한 것은 맞지만, <span style='background-color: #ffdce0'> 대부분의 QA 가 짧은 factoid QA </span> 로, "what","when","where","who" 등의 질문이 많고, "how", "why" 는 거의 존재하지 않는다.

최근 Open-domain QA 에서는 *Retrieve-then-read* 의 방식으로 relevant document 를 추출하고, 정답을 도출해내는 two stage 방법을 표방한 task 를 푼다.
그러나, 역시 대부분 짧은 factoid QA 에 국한 되어 있거나, jointly both stage 를 활용한다기보다는, <span style='background-color: #ffdce0'>  첫 번째 stage 에 relying 하는 경우가 대부분 </span>이다.

저자들의 **Think-aloud** Study 에서, <span style='background-color: #dcffe4'> scientific article </span>  을 읽고 full-stack reasoning 을 하는데는, surface question 에 추가적으로 testing 과 deep question 이 필요로 하다는 것을 드러낸다.
특히, surface question 에 대한 답을 하기 위해서는 첫 번째와 두 번쨰 stage reasoning 이 필요로함이 드러난다. 
이를 위해 저자들은, <span style='color:green;font-weight:bold'> Question Answering on Scientific Articles (QASA) </span> benchmark 를 제안한다. 
이 dataset 은 reader 와 author 에게 단편적인 단락만 읽게 하는게 아니라, *whole* paper 를 읽은 뒤 question 을 생성하게 한다.
추가적으로, *multi-faceted long-form* answer 로 답변하게 한다. 

QASA 의 예시는 위의 그림에서 볼 수 있다.
QASA 는  AI/ML paper 에서 1,798 개의 QA 를 포함하고 있으며, 위의 question schema 를 통해 deep reasoning level question 을 39.4\% 정도 보유한다.

실험은 세 가지로 진행한다. 위에서 언급한 두 개의 stage 에 대한 각각의 평가인, _associative selection_, _evidential rationale-generation_ 과 두 stage 를 모두 함께 잘하는 지 확인하는 _systematic composition_ 이다.
각각의 subtask 를 pretrained LLM 에 모델링하였을 때, InstructGPT (text-davinci-003) 을 ROUGE-1 기준 5.11 point 나 앞섰다.

# Related Work

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fc193c97-70d3-4f4b-afcf-ab69428ec38f)





<span style='background-color: #dcffe4'> 초록형광펜 </span>
<span style='background-color: #ffdce0'> 빨강형광펜 </span>
<span style='color:green;font-weight:bold'> 초록볼드체 </span>
