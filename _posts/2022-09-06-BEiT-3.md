---
layout: post
title:  "Image as a Foreign Language: BEIT Pretraining for All Vision and Vision-Language Tasks"
date:   2022-09-06 10:27:00 +0900
categories: [Vision-and-Language, Transformer]
---
[[pdf]](https://arxiv.org/pdf/2208.10442.pdf)  &emsp;
[[github]](https://github.com/microsoft/unilm/tree/master/beit) <br>

**Wenhui Wang, Hangbo Bao, Li Dong∗, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, Furu Wei**
<br>Mcirosoft Corporation

![image](https://user-images.githubusercontent.com/42200027/188531427-783fbf18-35b0-41f7-b9c1-2fc00162347e.png)
![image](https://user-images.githubusercontent.com/42200027/188532460-761fded0-75fe-464c-9d29-45d17ced21de.png)

# Abstract 

- Vision task 와 Vision-and-Language task 에서 State-of-the-Art 를 달성한 general-purpose model **BEIT-3** 을 소개한다.
- 논문에서 소개되는 General-purpose 를 위한 Multi-way Transformer 속의 modular arcitecture 가 deep fusion 과 modality-specific encoding 을 가능케 한다.
- Masked "language" modeling 을 image 에 적용한 **Imglish** 방법과 text, image-text pair 에 적용한 unified 방법으로 pretraining 함으로써, object detection(COCO), semantic segmentation(ADE20K), image classification(ImageNet), visual reasoning (NVLR2), visual question answering(VQAv2), Image captioning(COCO), 그리고 cross-modal retrieval(Flickr30K, COCO) 에서 모두 state-of-the-art 를 달성하였다.

# Introduction : The Big Convergence

최근 Language([BERT](https://arxiv.org/pdf/1810.04805.pdf)), Vision([BEIT](https://arxiv.org/pdf/2106.08254.pdf), [BEITv2](https://arxiv.org/pdf/2208.06366.pdf)), 그리고 Multimodal([VLMO](https://arxiv.org/pdf/2111.02358.pdf), [CLIP](https://arxiv.org/pdf/2103.00020.pdf), [Coca](https://arxiv.org/pdf/2205.01917.pdf)) 등의 강력한 Transformer 모델이 각 연구의 trend 를 이룬다.

그 중 Vision-and-Language task 에서는 세 가지 ***pretraining convergence trend*** 가 있다.

첫째로, Transformer 모델의 성공이 language 로 부터 vision, 그리고 multimodal 로 퍼지고 있다는 점이다. 그러나 Vision-and-Language 의 경우, downstream task 에 맞춰 Transformer 모델이 다른데, 직접 end-task format 을 Transformer의 구조에 맞춰줘야 한다는 단점이 있고, 또 paramtere 들이 modality 들을 잘 공유하지 못한다는 점이 있다. 이에 본 논문에서는 **[Multiway Transformers(BEIT)](https://arxiv.org/pdf/2106.08254.pdf)** 를 차용하여 
<span style='background-color: #dcffe4'> 하나의 통합된 모델이 다양한 donwstream task 를 푸는 </span> general-purpose 모델을 제안한다.

둘째로, Masked modeling 방법이 여러 모달리티에서도 성공을 거둔다는 점이다. 그러나 Pretraining task 를 위시한 masked modeling 방법에 대하여, 기존의 vision-and-language transformer 들은 image-text matching 같은 multitask 를 배우는데, 이러한 multitask pretraining 방법은 scaling-up 에 적합하지 않다. 따라서, 본 논문에서는 
<span style='color:green;font-weight:bold'> mask-then-predict </span> 의 간단한 방법을 통해 통합하였는데, 이는 image 를 ***Imglish*** 라는 하나의 foreign language 로 생각하여 [BERT](https://arxiv.org/pdf/1810.04805.pdf) 의 MLM(Masked Language Modeling) 과 같은 방식만 사용한다.

셋째로, model size 와 data size 를 키우는 것이 generalization quality 에 도움이 된다는 점이다. 본 논문에서는 이를 따라 수십억개(Billions)의 parameter 로 scaling-up 하였고, private data 없이 in-house data 만으로 큰 margin 으로 state-of-the-art 를 달성하였다.

![image](https://user-images.githubusercontent.com/42200027/188538934-5e22cb2f-d45f-41bd-9b8e-661ffa8b83f5.png)
본 논문에서는 위와 같이 Multiway Transformer 모델을 차용하는데, 앞서 언급한 것과 같이 text token 과 image patch 를 mask 한 후, predict 하는 self-supervised learning 방법만 이용한다. 첫 번째 그림과 표와 같이 본 논문에서 제시하는 <span style='color:green;font-weight:bold'> BEIT-3 </span> 모델이 많은 vision task 와 vision-and-language task 에서 state-of-the-art 를 달성하였다. 



<!--
```
pip install django-recaptcha
```

Add `'captcha'` to your `INSTALLED_APPS` setting.

```python
INSTALLED_APPS = [
    ...,
    'captcha',
    ...
]
```

Add the Google reCAPTCHA keys generated into your Django settings with `RECAPTCHA_PUBLIC_KEY` and `RECAPTCHA_PRIVATE_KEY`.

```python
RECAPTCHA_PUBLIC_KEY = 'MyRecaptchaKey123'
RECAPTCHA_PRIVATE_KEY = 'MyRecaptchaPrivateKey456'
```

Then modify the default authentication form with add new captcha field, in your `myapp/forms.py`:

```python
from django.conf import settings
from django.contrib.auth.forms import AuthenticationForm

from captcha.fields import ReCaptchaField
from captcha.widgets import ReCaptchaV2Checkbox


class AuthAdminForm(AuthenticationForm):

    if not settings.DEBUG:
        captcha = ReCaptchaField(widget=ReCaptchaV2Checkbox(
            attrs={
                'data-theme': 'light',
                'data-size': 'normal',
                # 'style': ('transform:scale(1.057);-webkit-transform:scale(1.057);'
                #           'transform-origin:0 0;-webkit-transform-origin:0 0;')
            }
        ))
```

Then in your `myproject/urls.py`;


```python
from django.contrib import admin
from django.urls import include, path

from myapp.forms import AuthAdminForm

# modify the default admin login form
# with add reCAPTCHA feature to fix bruteforce issue.
admin.autodiscover()
admin.site.login_form = AuthAdminForm
admin.site.login_template = 'account/admin/login.html'

urlpatterns = [
    path('admin/', admin.site.urls),
    ...
]
```

Also don't miss to add the captcha field into template `templates/account/admin/login.html`;

<iframe width="100%" height="400" src="//jsfiddle.net/agaust/ja21bugn/2/embedded/html/dark/" allowfullscreen="allowfullscreen" allowpaymentrequest frameborder="0"></iframe>
-->
