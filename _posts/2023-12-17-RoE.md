---
layout: post
title:  "[ICML2023] Exploring the Benefits of Training Expert Language Models over Instruction Tuning"
date:   2023-12-17 21:43:00 +0900
use_math: true
categories: [Transformer, PLM]
---

[[pdf]](https://openreview.net/pdf?id=VAA1itvsNQ)
[[github]](https://github.com/joeljang/ELM) 

**Joel Jang <sup>1*</sup>, Seungone Kim <sup>1*</sup>, Seonghyeon Ye <sup>1*</sup>, Doyoung Kim <sup>1*</sup>, Lajanugen Logeswaran <sup>2</sup>, Moontae Lee <sup>2,3</sup>, Kyungjae Lee <sup>2</sup>, Minjoon Seo <sup>1*</sup>**
<br><sup>1</sup> KAIST <sup>2</sup> LG AI Research <sup>3</sup> University of Illinois Chicago. Correspondence to: Joel Jang <joeljang@kaist.ac.kr>.
 &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/e1235d20-109d-4560-9e68-eddb787d689b)

# Abstract
- (Mutlitask prompting) LM 에 여러 가지 multitask 에 intruction tuning 을 진행하는 multitask prompted fine-tuning (MT) 을 useen task 에 대해서 좋은 능력을 보여왔다. 기존에, training task 의 수를 scaling 함으로써 성능 향상이 있다는 연구들이 많았다.
- (Motivation) 저자들은 놀랍게도, 단 하나의 task 에 fine-tuned 된 Expert LM 이 300 개 이상의 태스크로 학습된 MT-LM 과 비교하여, BIG-benchmark 의 13개에 대해서 1.29%, 11개의 unseed dataset 에 대해서 3.20% 의 성능 우위가 있음을 발견하였다.
- 이는 MT-LM 을 강력하게 하기 위해 task 의 수를 scaling 해야 한다는 기존의 연구에 의문점을 제시한다.
- 이에 더해 single MT-LM 을 대신해 task 별로 seperate expert LM 을 학습시키는 것이 zero-shot inference 에 도움이 될 수 있음을 보인다. 이는 (1) instruction tuning 과정에서 종종 일어나는 negative task transfer 를 방지하고, (2) re-train 이나 catastrophic forgetting 없이 continual learning 을 가능하게하며, (3) 각각의 expert 를 혼합하였을 때 *compositional* capability 를 보인다.


# Introduction

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/ddbe644a-86eb-48d0-8d85-3d18b9c39c98)

최근 Pretrained Language Model (PLM) 을 여러가지 task 에 instruction tuning 하는 MT-LM의 연구가 활발하다.
이는 성능이 매우 좋다고 알려져 있다.
그러나, 이 연구에서는 두 가지 파트로 나누어 MT-LM 의 current paradigm 에 의문점을 던진다.

<span style='color:green;font-weight:bold'> Part1  </span><br>

기존에는 MT-LM 의 unseen task 에 대한 generalization 능력은 training 과정에서 배운 task 수에 scaling 한다는 연구가 많았다. 
<span style='background-color: #dcffe4'> 그러나 이 연구에서 우연히도, 단 하나의 task 를 배운 expert LM 이 300 개 이상의 task 를 배운 T0-3B 를 non-trivial margin 으로 이긴 것을 발견하였다. </span>

이에 저자들은 T0-3B 를 학습시킨 296 개의 task 를 각각 하나씩만 배우게 expert LM 들을 학습시켰다.
이 296 개 중 7 개의 expert LM 이 T0-3B 의 unseen task 에 대해 더 높은 성능을 보인다(Figure 1).
이 7 개의 expert 로 부터 11개의 unseen task 를 측정했을 때 3.2%, Big bnech 에서는 1.29% 성능 우위를 보였다.
저자들은 또한 relevant expert 를 retrieve 하는 간단한 메커니즘을 통해 각각의 unseen task 에서 T0-3B 를 압도하는 성능을 얻을 수 있음을 보인다.
무려 12% 에 까까운 improvement 를 통해, 단순히 single MT-LM 을 나이브하게 학습시키는 것보다, 올바른 expert 를 choosing 하는 것이 더욱 효과적이고 효율적인 방법이라는 것을 보인다.

<span style='color:green;font-weight:bold'> Part2  </span><br>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/9218d8d1-6945-4f07-a5e0-d42c3b67e5b0)

저자들은 위의 발견 외에도 RoE (Retrieval of Expert)가 MT-LM 보다 나은 세 가지 다른 advantage 를 발견한다.
