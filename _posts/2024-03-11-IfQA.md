---
layout: post
title:  "[EMNLP2023] IfQA: A Dataset for Open-domain Question Answeringunder Counterfactual Presuppositions"
date:   2024-03-11 18:00:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://aclanthology.org/2023.emnlp-main.515.pdf) &emsp;
[[github]](https://allenai.org/data/ifqa)

**Wenhao Yu<sup>♦</sup>, Meng Jiang<sup>♣</sup>, Peter Clark<sup>♠</sup>, Ashish Sabharwal<sup>♠</sup>**
<br><sup>♦</sup> Tecent AI Seattle Lab <sup>♣</sup> University of Notre Dame <sup>♠</sup> Allen Institute for AI &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/dc04e304-b2b0-44e5-8293-aee477bbaa0e)

# Abstract
- (**lack of counterfactual QA dataset**) counterfactual reasoning 이 매우 중요하지만, large-scale counterfactual open-domain question answering (QA) dataset 이 부족하여, model 을 평가하기 힘들다.
- (<span style='color:green;font-weight:bold'> IfQA </span>) 모든 question 이 'if' 를 통한 **counterfactual presupposition** 에 기반한 IfQA 벤치마크를 introduce 한다. 이 Question 들은 parameter 속의 진실과 반대되는 imagined situation 에 대해서도 right information 을 identify 할 수 있어야한다.
- (**Experiment**) supervised retrieve-then-read pipeline 모델들에 대하여, 낮은 점수를 보이며, ChatGPT 를 활용한 Chain-of-Thought 을 활용해도 여전히 challenging 한 open-domain QA benchmark 이다.

## 1. Introduction
<span style='color:green;font-weight:bold'> ▶Counterfactual reasoning </span>
<br>
<span style='background-color: #dcffe4'> 
Counterfactual reasoning 은 실제 일어났거나 factually true 와 반대되는 어떠한 일들의 연속에 대해 possible alternative 를 imagine 하는 human tendency 를 뜻한다. </span>
예를 들어, business area 의 corporate leader 들은 alternative investment strategy 를 취했을 때의 potential ripple effect 를 고려하여 의사결정을 하는데, 이러한 가정이 counterfactual reasoning 이다.
AI 모델이 이러한 반대되는 가정을 할 수 있는 능력을 갖추는 것은 매우 중요하지만, <span style='background-color: #ffdce0'> 현재 open-domain QA Task 에서 이러한 counterfactual 가정을 다루는 task 는 전무하다. </span>
대부분의 open-domain QA 는 internet 등의 global resource 에서 정보를 취득할 수 있는 question 을 푸는 것에 집중할 뿐이다.

그러나, **counterfactual presupposition** 은 causal intervention 으로 해석될 수 있는데, given presupposition 에 대해 human reader 들 사이의 shared background knowledge 를 따라야만 하기 때문이다.
모델들은 이러한 imagined situation 에 대해서도 정확한 정보를 retrieve 한 후 해석을 할 수 있는 능력을 갖추어야 한다.

<span style='color:green;font-weight:bold'> ▶ IfQA </span>
<br>
몇몇의 연구에서 counterfacutal evidence 가 주어졌을 때, 이것을 인지(identify)하고 수정(correct)하려는 시도의 연구가 있었지만, <span style='background-color: #ffdce0'> open-domain QA scenario 에서 counterfactual reasoning capability 를 발전시키고 평가하려는 시도 자체가 없었다. </span>
이에 저자들은, **IfQA** 라 불리는 3,800 개의 질문들로 이뤄진 counterfactual presupposition benchmark dataset 을 만들어제안한다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/8062eb89-6200-48e8-82f6-a8b7b676e303)

위의 Figure 에서 예시를 볼 수 있다. IfQA 는 causal inference question 을, factual text sources 와 결합한다. 

<span style='background-color: #dcffe4'> 
IfQA 는 retrieval 과 reading 에서 새로운 challenge 를 제안한다.
 </span>
예를 들어, 위의 figure 의 2번째 예시에서, search-reasoning 과정은 네 개의 스텝으로 나뉜다.
(i) [search] 에베레스트 산의 현재 높이 (8848M) , (ii) [calculate] 8848-300 = 8548, (iii) [retrieve] second-heighst mountain K2's 현재 높이 (8611M), (iv) [compare] 두 산 중 높은 산의 높이를 generate : K2

<span style='color:green;font-weight:bold'> ▶ Experiment </span>
<br>
IfQA 에서 inital performance level 을 확립하기 위해, 즉 baseline 성능을 제시하기 위해, 저자들은 state-of-the-art close-book and open-book model 을 평가한다.
Closed-book model 로는 ChatGPT 의 CoT 능력을 활용하고, open-book model 로는 RAG 와 FiD 와 같은 retrieve-then-generate 모델을 활용한다.

실험 결과, IfQA가 retrieval 과 reading 에서 모두 challenging 한 dataset 임을 보인다.
특히 몇 가지 특별한 발견을 하는데, **(1)** retireval 에서 semantic matching 을 기반으로하는 전통적인 dense retrieval method 는 counterfactual presupopsition 과 실제 factual evidence 사이의 discrepancy 를 잘 capture 할 수 었었으며, **(2)** FiD 와 같은 state-of-the-art reader model 들은 gold passage 가 주어져도 50% 정도의 F1 score 를 기록할 정도로 어려워했다. 또한, **(3)** closed-book CoT reasoning 은 end-QA performance 를 향상시킬 수 있었지만, 여전히 open-book model 보다 성능이 매우 뒤쳐진다. 마지막으로, **(4)** passage retreival 과 large model reasoner 를 결합하는 것이 가장 좋은 성능을 보인다는 것을 보인다.


## 2. IfQA : Task and Dataset
# 2.1. Dataset Collection
모든 dataset collection 은 Amazon Mechanical Turk (AMT) 를 활용하여 이뤄졌다.
※ 자세한 크라우드소싱 관련 내용은 논문 참고.

Annotation protocol 은 아래의 세 가지 과정으로 이뤄진다. 
우선, (i) counterfactual qeustion 을 수정할 수 있을 것 같은 Wikipedia 로 부터 passage 를 extract 한다. (ii) 이후, 크라우드소싱을 활용하여 counterfactual reasoning 을 만들고 (iii) additonal worker 를 통해 correctness 와 quality 를 평가한다. Annotation 을 위한 task form 은 아래와 같다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/55ae1215-d720-46c7-9ff4-551d465d8a77)

<span style='color:green;font-weight:bold'> (1) Question and Answer Annotation </span>
<br>
- **Passage Selection**
우선, Wikipedia 에서 causal event 와 관련된 passage 만 filter out 하여 남긴다. Specifically, <span style='background-color: #dcffe4'> "lead to, cause, becuase, due to, originally, initially" 와 같은 causality keyword 를 활용하여 filtering 을 진행한다. </span>
Randomly selected passage 와 비교하여, 이러한 filtering 기법이 question annotation 의 difficulty 를 압도적으로 낮춰준다고 주장한다.

- **Question Annotation**
Human Intelligence Task (HIT) 의 question annotation process 에서 유연성을 확보하기 위하여, worker 들은 20 개의 Wikipedia passage 중 10개의 passage 를 골라서 question 을 annotate 할 수 있다.
(Worker 들에게 몇 개의 example 이 제공될 때 question 의 quality 가 좋으며, 유연하게 다양한 example 이 주어지면 더 좋은 quality 의 question 이 생성되었다고 한다)
Diverse 한 question example 이 주어지지 않으면 worker 들이 기존의 question 을 mimic 하려고만 하는 경향이 있어서, annotation task 의 example 을 다양하게 만들어서 그 중 5개 정도를 보여주었다고 한다.
또한, free-form 으로 question 을 작성하게하여, template 에 국한되지 않게끔 유도하였으며, 20.6% 정도의 question 이 free-form 으로 생성되었다고 한다.

- **Answer Annotation**
마지막으로, 생성된 question 에 대하여 appropriate 한 경우에 한하여 valid answer 를 작성하게 한다.

<span style='color:green;font-weight:bold'> (2) Question and Answer Verification </span>
<br>
Quetion verification 은 아래의 세 가지 질문을 통해 이뤄진다.
- **Q1: Is this a readable, passage-related question?**

- **Q2: Is the question not well-defined without the Wikipedia passage?**

- **Q3: Is the given answer correct? If not, could you provide the correct answer to the question?**

<span style='color:green;font-weight:bold'> (3) Answer Post-processing </span>
<br>
Question 과 Answer 가 free-form 으로 작성되었기 때문에 Formalize 등의 post-processing 과정을 거친다.
예를 들어, "USA", "U.S.A" 등 다양한 alias 경우를 "United States of America" 로 통일하거나, "5" 를 "five" 로, "30" 을 "thrity" 로 통일하는 등의 간단한 후처리 작업을 진행한다.

# 2.2. Dataset Analysis
<span style='color:green;font-weight:bold'> Answer Type and Length </span>
<br>
<span style='background-color: #dcffe4'> IfQA Benchmark 는 Answer 를 기준으로 네 가지 type 으로 나뉜다 : entity(49.7%), datae (14.5%), number(15.9%), others (19.9%) </span> 아래의 표에서 예시들을 볼 수 있다. Answer 들은 평균 1.82 words 정도의 짧은 답변으로 이뤄진다 (*NQ (2.35 words), TriviaQA
(2.46 words), and HotpotQA (2.46 words) 에 비해 짧은 answer*)

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/1fe5b5d3-1b91-4670-9a8e-616d13810259)


<span style='color:green;font-weight:bold'> Question Type and Length </span>
<br>

<span style='color:green;font-weight:bold'> Span vs. Non-span Answer </span>
<br>



# 2.3. Dataset Splits

## 3. Experiments
# 3.1. Retrieval Corpus

# 3.2. Comparison Systems

# 3.3. Evaluation Metrics

# 3.4. Implementation Details

# 3.5. Results and Discussion
<span style='color:green;font-weight:bold'> (1) Retrieval in IfQA is challenging. </span>
<br>

<span style='color:green;font-weight:bold'> (2) Reading and reasoning in IfQA are challenging. </span>
<br>

<span style='color:green;font-weight:bold'> (3) Chain-of-thought improves LLMs’ counterfactual reasoning. </span>
<br>

<span style='color:green;font-weight:bold'> (4) Passage retriever + Large model reasoner
performs the best on IfQA. </span>
<br>

## Conclusion

## Limitations



<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
