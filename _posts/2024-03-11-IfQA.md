---
layout: post
title:  "[EMNLP2023] IfQA: A Dataset for Open-domain Question Answeringunder Counterfactual Presuppositions"
date:   2024-03-11 18:00:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://aclanthology.org/2023.emnlp-main.515.pdf) &emsp;
[[github]](https://allenai.org/data/ifqa)

**Wenhao Yu<sup>♦</sup>, Meng Jiang<sup>♣</sup>, Peter Clark<sup>♠</sup>, Ashish Sabharwal<sup>♠</sup>**
<br><sup>♦</sup> Tecent AI Seattle Lab <sup>♣</sup> University of Notre Dame <sup>♠</sup> Allen Institute for AI &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/dc04e304-b2b0-44e5-8293-aee477bbaa0e)

# Abstract
- (**lack of counterfactual QA dataset**) counterfactual reasoning 이 매우 중요하지만, large-scale counterfactual open-domain question answering (QA) dataset 이 부족하여, model 을 평가하기 힘들다.
- (<span style='color:green;font-weight:bold'> IfQA </span>) 모든 question 이 'if' 를 통한 **counterfactual presupposition** 에 기반한 IfQA 벤치마크를 introduce 한다. 이 Question 들은 parameter 속의 진실과 반대되는 imagined situation 에 대해서도 right information 을 identify 할 수 있어야한다.
- (**Experiment**) supervised retrieve-then-read pipeline 모델들에 대하여, 낮은 점수를 보이며, ChatGPT 를 활용한 Chain-of-Thought 을 활용해도 여전히 challenging 한 open-domain QA benchmark 이다.

## 1. Introduction
<span style='color:green;font-weight:bold'> ▶Counterfactual reasoning </span>
<br>
<span style='background-color: #dcffe4'> 
Counterfactual reasoning 은 실제 일어났거나 factually true 와 반대되는 어떠한 일들의 연속에 대해 possible alternative 를 imagine 하는 human tendency 를 뜻한다. </span>
예를 들어, business area 의 corporate leader 들은 alternative investment strategy 를 취했을 때의 potential ripple effect 를 고려하여 의사결정을 하는데, 이러한 가정이 counterfactual reasoning 이다.
AI 모델이 이러한 반대되는 가정을 할 수 있는 능력을 갖추는 것은 매우 중요하지만, <span style='background-color: #ffdce0'> 현재 open-domain QA Task 에서 이러한 counterfactual 가정을 다루는 task 는 전무하다. </span>
대부분의 open-domain QA 는 internet 등의 global resource 에서 정보를 취득할 수 있는 question 을 푸는 것에 집중할 뿐이다.

그러나, **counterfactual presupposition** 은 causal intervention 으로 해석될 수 있는데, given presupposition 에 대해 human reader 들 사이의 shared background knowledge 를 따라야만 하기 때문이다.
모델들은 이러한 imagined situation 에 대해서도 정확한 정보를 retrieve 한 후 해석을 할 수 있는 능력을 갖추어야 한다.

<span style='color:green;font-weight:bold'> ▶ IfQA </span>
<br>
몇몇의 연구에서 counterfacutal evidence 가 주어졌을 때, 이것을 인지(identify)하고 수정(correct)하려는 시도의 연구가 있었지만, <span style='background-color: #ffdce0'> open-domain QA scenario 에서 counterfactual reasoning capability 를 발전시키고 평가하려는 시도 자체가 없었다. </span>
이에 저자들은, **IfQA** 라 불리는 3,800 개의 질문들로 이뤄진 counterfactual presupposition benchmark dataset 을 만들어제안한다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/8062eb89-6200-48e8-82f6-a8b7b676e303)

위의 Figure 에서 예시를 볼 수 있다. IfQA 는 causal inference question 을, factual text sources 와 결합한다. 

<span style='background-color: #dcffe4'> 
IfQA 는 retrieval 과 reading 에서 새로운 challenge 를 제안한다.
 </span>
예를 들어, 위의 figure 의 2번째 예시에서, search-reasoning 과정은 네 개의 스텝으로 나뉜다.
(i) [search] 에베레스트 산의 현재 높이 (8848M) , (ii) [calculate] 8848-300 = 8548, (iii) [retrieve] second-heighst mountain K2's 현재 높이 (8611M), (iv) [compare] 두 산 중 높은 산의 높이를 generate : K2

<span style='color:green;font-weight:bold'> ▶ Experiment </span>
<br>
IfQA 에서 inital performance level 을 확립하기 위해, 즉 baseline 성능을 제시하기 위해, 저자들은 state-of-the-art close-book and open-book model 을 평가한다.
Closed-book model 로는 ChatGPT 의 CoT 능력을 활용하고, open-book model 로는 RAG 와 FiD 와 같은 retrieve-then-generate 모델을 활용한다.

실험 결과, IfQA가 retrieval 과 reading 에서 모두 challenging 한 dataset 임을 보인다.
특히 몇 가지 특별한 발견을 하는데, **(1)** retireval 에서 semantic matching 을 기반으로하는 전통적인 dense retrieval method 는 counterfactual presupopsition 과 실제 factual evidence 사이의 discrepancy 를 잘 capture 할 수 었었으며, **(2)** FiD 와 같은 state-of-the-art reader model 들은 gold passage 가 주어져도 50% 정도의 F1 score 를 기록할 정도로 어려워했다. 또한, **(3)** closed-book CoT reasoning 은 end-QA performance 를 향상시킬 수 있었지만, 여전히 open-book model 보다 성능이 매우 뒤쳐진다. 마지막으로, **(4)** passage retreival 과 large model reasoner 를 결합하는 것이 가장 좋은 성능을 보인다는 것을 보인다.








## 2. IfQA : Task and Dataset
# 2.1. Dataset Collection
<span style='color:green;font-weight:bold'> (1) Question and Answer Annotation </span>
<br>

<span style='color:green;font-weight:bold'> (2) Question and Answer Verification </span>
<br>

<span style='color:green;font-weight:bold'> (3) Answer Post-processing </span>
<br>


# 2.2. Dataset Analysis
<span style='color:green;font-weight:bold'> Answer Type and Length </span>
<br>


<span style='color:green;font-weight:bold'> Question Type and Length </span>
<br>

<span style='color:green;font-weight:bold'> Span vs. Non-span Answer </span>
<br>



# 2.3. Dataset Splits

## 3. Experiments
# 3.1. Retrieval Corpus

# 3.2. Comparison Systems

# 3.3. Evaluation Metrics

# 3.4. Implementation Details

# 3.5. Results and Discussion
<span style='color:green;font-weight:bold'> (1) Retrieval in IfQA is challenging. </span>
<br>

<span style='color:green;font-weight:bold'> (2) Reading and reasoning in IfQA are challenging. </span>
<br>

<span style='color:green;font-weight:bold'> (3) Chain-of-thought improves LLMs’ counterfactual reasoning. </span>
<br>

<span style='color:green;font-weight:bold'> (4) Passage retriever + Large model reasoner
performs the best on IfQA. </span>
<br>

## Conclusion

## Limitations



<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
