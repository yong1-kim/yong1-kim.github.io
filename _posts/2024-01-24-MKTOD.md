---
layout: post
title:  "[EMNLP2023] Retrieval-Generation Alignment for End-to-End Task-Oriented Diaogue System"
date:   2024-01-12 17:00:00 +0900
use_math: true
categories: [Retrieval, Dialogue]
---

[[pdf]](https://arxiv.org/pdf/2305.06983.pdf) &emsp;
[[github]](https://github.com/jzbjyb/FLARE)

**Weizhou Shen<sup>1</sup>, Yingqi Gao<sup>1</sup>, Canbin Huang<sup>1</sup>, Fanqi Wan<sup>1</sup>, Xiaojun Quan<sup>1*</sup>, Wei Bi<sup>2*</sup>**
<br><sup>1</sup> School of Computer Science and Engineering, Sun Yat-sen University, China <sup>2</sup> Tencent AI Lab &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/00c7778c-3dc1-415c-a07a-6e6b0539cab6)

## Abstract
- (**Retrieval for TOD**) Localized and specialized task 를 효과적으로 처리하기 위해, Task-Oriented Dialogue(TOD)은 Knowledge Base (KB) 에서 정보를 Retrieval 해온다.
- (**Retrieval Error**) 그러나, ChatGPT 나 T5 등의 generative model 이 KB record 에서 retrieved 된 정보를 처리할 때, 사소한 차이점으로 인한 잘못된 결과를 생성해낸다.
- (**Proposed Method**) 이 논문에서는 maximal marginal likelihood 를 사용하여, response generation 으로부터의 signal 을 통해 perceptive retriever 를 학습시킨다.
- (**Experiment**) 이 방법으로 학습된 retriever 를 T5 와 ChatGPT 를 backbone 으로 하여 싫머을 진행하였을 떄, high-quality 의 knowledge record 로 부터, 좋은 response 를 generate 하는 것을 검증한다.

## 1.Introduction

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/713638ed-3f2c-4c7d-9d36-5f69bb4bc8a7)

<span style='color:green;font-weight:bold'> TOD : Task-Oriented Dialogue System </span>
<br>
Task-Oriented Dialogue System (TOD)은 기차 예약, 스케쥴 조정 등 특정한 목표를 수행을 돕는 시스템이다.
보통 TOD 는 pipeline 과 End2End 형식으로 나뉘는데, DST, Policy 등의 모듈이 나눠져 파이프라인 형식으로 진행이 되거나, 중간 개입 없이 한 번에 response 를 generate 하는 방식이 각각 그것들이다.
Pipeline 모델과 그 각 모듈들에 대한 연구가 성행하다가, <span style='background-color: #dcffe4'>  최근 Large Language Model (LLM) 의 출현 덕분에, End2End 모델에 대한 관심도가 급증 </span> 하고 있다.

<span style='color:green;font-weight:bold'> RAG : Retrieval-augmented generation </span>
<br>
Retrieval-augmented generation (RAG) 은 result 를 generate 하기 위해 외부 지식을 retrieval 하여 활용하는 것을 말한다.
[Q-TOD](https://arxiv.org/pdf/2210.07564.pdf) 에서는 E2E-TOD 에 RAG 방법을 적용하여 기존의 방법들을 훨씬 뛰어넘는 성능을 보였다.
하지만 저자들의 preliminary study 에 따르면, <span style='background-color: #dcffe4'> knowledge retriver 의 perofrmance 와 reponse generator 의 performance 사이의 correlation 은 상당히 약하며, </span> 이 것은 **retriever 을 imporve 한다고 해서 전체적인 generation 성능이 좋아지는 것은 아니라는 것**을 의미한다.
저자들은 이 현상을 <span style='color:green;font-weight:bold'> misalignment </span> between retireval and generation 이라고 명명한다. 이 현상이 최근 E2E-TOD 의 발목을 잡는 bottleneck 이다.

<span style='color:green;font-weight:bold'> Qualitative analysis </span>
<br>
Qualitative analysis 로, 저자들은 이 misalignment 는 <span style='background-color: #dcffe4'> homegeneity of retreived knowledge entity </span>  때문이라고 가정한다.
위의 Figure 1 과 같이, retrieved 되어 온 entity 들은 약간의 차이점을 제외하고, 높은 수준의 유사성을 보인다.
결과적으로, reponse generator 는 knowledge-related token 보다, 학습된 language token 에 predominant 하게 반응하여 결과를 생성해낸다고 본다.

<span style='color:green;font-weight:bold'> MK-TOD : Meta Knowledge for TOD </span>
<br>
이에 저자들은 **M**eta **K**nowledge for end-to-end **T**ask-**O**riented **D**ialogue system (**MK-TOD**) 을 제안한다.
MK-TOD 는 언급된 misalignment 를 해결하는 것을 목표로 한다.
우선, [maximal marginal likelihood](https://proceedings.neurips.cc/paper_files/paper/2021/file/da3fde159d754a2555eaa198d2d105b2-Paper.pdf) 방법을 통해 retriever 가 학습 과정 내내 progressive 하게 학습되도록 하였고, response generator 가 entity 들을 잘 구분하게 하기 위하여, **meta knowledge** 를 사용할 수 있는 능력을 갖추게 한다.
여기서, meta knowledge 는 retrieval 에 관련된 추가 정보로, retrieval order, retrieval confidence, co-occurrence rate 으로 이뤄진다.
Meta knowledge 는 세 가지 접근법을 통해 학습을 진행해 보는데, (1) special prefix token 을 추가, (2) prompt 활용, (3) contrastive learning 적용이다. 
또 추가적으로 generator 가 discriminative ability 를 갖게 하기 위하여, negative knowledge 를 사용하는 방법도 실험한다.


<span style='color:green;font-weight:bold'> Experiment </span>
<br>




<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
