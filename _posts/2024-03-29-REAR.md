---
layout: post
title:  "[Arxiv 2402] REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
date:   2024-03-29 00:01:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2402.17497.pdf)  &emsp;
[[github]](https://github.com/RUCAIBox/REAR)

**Yuhao Wang<sup>1∗</sup>, Ruiyang Ren<sup>1∗</sup>, Junyi Li<sup>1,3</sup>, Wayne Xin Zhao<sup>1†</sup>, Jing Liu<sup>4†</sup>, Ji-Rong Wen<sup>1,2</sup>**
<br><sup>1</sup> Gaoling School of Artificial Intelligence, Renmin University of China <sup>2</sup> School of Information, Renmin University of China <sup>3</sup> DIRO, Université de Montréal <sup>4</sup> Baidu Inc. &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/87f16237-fa93-4425-b0bf-cb7e00bd12be)

# Abstract
- (**RAG and Weakness**) Internal parametric knowledge 의 한계를 극복하기 위해, Retrieval-augmented generation (RAG) 이 활발히 연구되고 있다. 그러나, RAG 에서 LLM 이 retrieved document 의 relevance 를 정확하게 평가할 수 없어, 오히려 RAG 가 옳지 못한 결과를 추출하는 경우가 있다.
- (<span style='color:green;font-weight:bold'> REAR </span>) 이 문제를 해결하기 위해, 저자들은 REAR:Relevance-Aware Retireval augmented approach 를 제안한다. LLM 으로 하여금 source relevance 의 self-awareness 를 발전시키고, 이를 RAG 시스템에서 잘 활용할 수 있게 한다. 구체적으로, **rank head** 를 이용하는 방법을 활용한다.
- (**Experiment**) 네 개의 open-domain QA (ODQA) 에서 기존의 RAG 방법들 보다 압도적으로 뛰어난 성능을 보인다.

## 1. Introduction

<span style='color:green;font-weight:bold'> ▶ Retrieval-Augmented Generation (RAG)</span>
<br>
Large Language Model (LLM) 이 여러 task 에서 좋은 성능을 보여주지만, open-domain QA (ODQA) 와 같은 knowledge-intensive task 에 대해서는 고전(struggle)하는 경향이 있다.
이를 위해, external knowledge 를 retrieval 해와서 generation 에 도움을 주도록 하는 Retrieval-augmented generation (RAG) 에 대한 연구가 활발하다. 

그러나, RAG 를 활용한 점에도 단점이 존재한다.
첫째로, <span style='background-color: #ffdce0'> retrieved result 가 irrelevant content 를 포함하고 있 을 경우, LLM 을 mislead 하여 정확하지 않은 답변이 생성된다([[1]](https://aclanthology.org/2023.acl-long.546.pdf),[[2]](https://arxiv.org/pdf/2307.11019.pdf)) </span>
또한, <span style='background-color: #ffdce0'> 성능향상을 위해 여러 문서를 retrieval 해올 경우 noise 가 영향을 미치기도 한다.([[3]](https://arxiv.org/pdf/2307.03172.pdf),[[4]](https://arxiv.org/pdf/2302.00093.pdf)) </span>
**따라서, LLM 은 irrelevant document 를 filtering 하면서 noisy content 를 피해야하는 문제점에 직면하고 있다.**

<span style='color:green;font-weight:bold'> ▶ Enhancing Robustness of RAG system </span>
<br>
최근 여러 연구([SELF-RAG[5]](https://arxiv.org/pdf/2310.11511.pdf),[SAIL[6]](https://arxiv.org/pdf/2305.15225.pdf),[RobustLM[7]](https://arxiv.org/pdf/2310.01558.pdf)) 에서 RAG 의 robustness 를 발전시키려는 시도들이 있다.
Self-RAG 의 경우, special token 을 활용해 document 가 relevant 한지를 discriminate 하여 generation 단계에서 활용 여부를 결정하고, RobustLM 은 document 가 relevant 한지 discriminate 하도록 LLM 을 prompting 한 이후 generation 을 진행한다.
<span style='background-color: #ffdce0'> 그러나, 이 방식들은 document relevance 를 binary label 로 분류하기 때문에, highly sparse 하고 fine-grained relevance 를 capture 하지 못한다.  </span>

<span style='color:green;font-weight:bold'> ▶ REAR: Relevance-Aware Retireval-augmented Approach </span>
<br>
이에 저자들은 **REAR**:**RE**levance-**A**ware **R**etireval-augmented Approach 방법을 제안한다.
<span style='background-color: #dcffe4'> 이 방법론의 골자는 LLM 으로 하여금 source relevance 에 대한 self-awareness 를 발전시키고, LLM 이 스스로 external knowledge 를 adaptive 하게 활용하게 하는 것이다. </span>

REAR 는 모델 아키텍쳐와 모델 학습 방법에 main contribution 이 존재한다.
우선, Information Retrieval (IR) 필드에서 성공한 reranker 방식을 이용하여, LLM 에 **rank head** 를 디자인하여 relevance assessment 를 하게 하여, irrelevant external knowledge 로 부터의 distraction 을 피하도록 돕는 relevance signal 을 capture 한다.
두번째로, coarse-grained signal 인 bianry discriminative method 의 한계점을 극복하기 위하여, **bi-granularity relevance fusion** 방식을 적용하여 fine-grained supervision 을 포함시키고, noise-resistant training 을 통해 discrimination ability 를 향상시킨다.

실험 결과, 네 개의 open-domain QA (ODQA) task 에서 REAR 가 좋은 성능을 보여준다.

## 2. Related Work
# 2.1. Open-domain Question Answering

# 2.2. Retrieval-augmented LLMs

## 3. Task Formulation

## 4. Methodology
# 4.1. Relevance-Aware RAG Architecture
<span style='color:green;font-weight:bold'> (1) Relevance Assessment </span>
<br>

<span style='color:green;font-weight:bold'> (2) Relevance-guided Generation </span>
<br>

<span style='color:green;font-weight:bold'> (3) Final Answer Routing </span>
<br>

# 4.2. Model Training


<span style='color:green;font-weight:bold'> (1) Bi-granularity Relevance Fusion </span>
<br>

<span style='color:green;font-weight:bold'> (2) Noise-resistant Training </span>
<br>

<span style='color:green;font-weight:bold'> (3) Training Data Construction </span>
<br>


# 4.3. Model Discussion

## 5. Experiments
# 5.1. Experimental Setup

# 5.2. Main Results

# 5.3. Detaild Analysis
<span style='color:green;font-weight:bold'> (1)  Ablation Study </span>
<br>

<span style='color:green;font-weight:bold'> (2)  Impact of Retrieved Documents </span>
<br>

## 6. Conclusion
```
In this paper, we aimed to enhance the selfawareness of source relevance in RAG systems, and proposed REAR, a RElevance-Aware Retrievalaugmented approach for open-domain question answering (QA). For model architecture, we explicitly incorporated a specially designed rank head to precisely capture the relevance signals, and employed it to guide the utilization of external knowledge. For model training, we designed an improved training method with bi-granularity relevance fusion and noise-resistant training, which enhance the capacities of fine-grained relevance assessment and adaptive use of retrieved documents. Extensive experiments on four datasets demonstrate the effectiveness of REAR’s relevance assessment and knowledge utilization.
As future work, we will extend the proposed approach REAR to dealing with more fine-grained source utilization (e.g., passage or sentence level augmentation), and also consider applying REAR to other knowledge-intensive tasks.
```
## Limitations
```
For LLMs, the challenge of being misled by irrelevant retrieved documents is a significant obstacle, underscoring the crucial need for enhancing LLMs’ ability to adaptively utilize retrieved documents. In response to this issue, our work has concentrated on refining the architecture and training methods to bolster the effective use of retrieved documents by LLMs. We have implemented document-level relevance assessment and dynamic utilization strategies, significantly boosting the factual accuracy of generated content by LLMs. However, our current approach has not delved into guiding LLMs to focus more granularly on key sentences or tokens within the retrieved documents.
Moreover, the applicability of our methods across a broader spectrum of RAG tasks, such as those encompassed by the KILT benchmark, remains to be thoroughly evaluated. This gap presents a pivotal area for our future investigations.
```



<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>

<span style='color:green;font-weight:bold'> ▶ </span>
<br>
