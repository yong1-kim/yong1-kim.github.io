---
layout: post
title:  "[NeurIPS2023] Meta-in-context learning in large language models"
date:   2024-01-10 12:42:00 +0900
use_math: true
categories: [LLM]
---

[[pdf]](https://openreview.net/pdf?id=sx0xpaO0za)
[[github]](https://github.com/yandachen/In-context-Tuning)

**Julian Coda-Forno <sup>1,2,∗</sup>, Marcel Binz <sup>1</sup>, Zeynep Akata <sup>2</sup>, Matthew Botvinick <sup>3</sup>, Jane X. Wang <sup>3</sup>, Eric Schulz <sup>1</sup>**
<br><sup>1</sup> Max Planck Institute for Biological Cybernetics, <sup>2</sup> University of Tübingen - Tübingen, Germany <sup>3</sup> Google DeepMind - London, United-Kingdom &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/72321483-0834-465e-959d-1f2da731f4c4)

# Abstract
- (**Meta in-context learning**) in-context leraning 능력이 in-context learning 자신을 통해 recursive 하게 발전되는 방법론인 <span style='color:green;font-weight:bold'>  meta in-context learning </span> 을 소개한다. 
- (Idealized Domain) Regression task 와 two-armed bandit task 를 통해, meta-in-context learning 이 large language model 의 prior 의 expected task 에 adaptively reshape 한다.
- (Experiment) real-world regression problem 과 다양한 NLP task 에 대해, 기존의 learning 알고리즘과 비교하여 경쟁적인 성능을 보인다.

# Introduction
LLM 은 in-context learning 을 통해 additional training 없이도 대학수준의 수학 문제를 푼다던지, 어려운 reasoning task 를 해결할 수 있다. 이러한 것은 in-context learning (or few-shot prompting or few-shot learning) 이라 불리는 능력으로 알려져 있는데, downstream task 에 finetuning 을 진행하는 traditional 한 방식과는 차이를 보인다.

본 연구에서 저자는 <span style='color:green;font-weight:bold'>  whether the learning algorithm implemented through in-context learning can be improved through in-context learning itself  </span> 에 대한 질문을 한다.
이를 본 논문에서는 <span style='color:green;font-weight:bold'> meta-in-context learning </span> 이라고 칭한다.

세 개의 세팅에서, in-context learning 능력이 in-context learning 을 통해 발전된다는 evidence 를 찾는다.
우선 artifical domain 으로써, 하나의 regression task 와 하나의 two-armed bandit task 를 풀어본 결과, LLM 에게 sequential 하게 multiple learning problem 을 주는 것이 in-context learning 능력을 발전시키는 것을 확인할 수 있다.
이후, idealized domain 의 실험에서,<span style='background-color: #dcffe4'>  meta-in-context learning 이 latnet variable 의 prior 를 수정하여, 환경의 true statistics 에 유사하게 바뀐다는 것을 발견한다. 추가적으로, LLM 의 leraning strategy 자체를 reshaping 하는 것도 발견한다. </span>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/060dcf89-38c3-4ff7-a9a4-6257a9ffdc89)

위의 그림이 meta-in-context learning 의 high-level overview 이다.
Task 를 점진적으로 부여함으로써, 이전의 in-context learning 이 다음 in-context learning 에 영향을 주는 것이 meta-in-context learning 이다.

# Experimental Setup
- GPT-3 (text-davinci-002)
- temperature 0 for deterministic response

# Learning one-dimensional functions
우선 첫 실험 세팅으로, one-dimensional regression task 를 선택한다.

<span style='background-color: #dcffe4'> (1) Method </span>

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/c7e36cc4-bcd5-433a-8b8b-d1bc729eea2c)

위의 예시처럼, 5 개의 task 에 대해서, T 개의 pair 들이 들어가고, 마지막 pair 의 y 값을 맞추는 task 이다.
모든 pair 는 x 와 y 의 noise $\epsilon$이 추가된 linear function (y = a*x + b + $\epsilon$) 이다.

<span style='background-color: #dcffe4'> (2) Results </span>

실험 결과는 아래와 같다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/418cce1d-12ac-4054-99bb-cc532d5fbc2c)

우선, 기존의 preliminary simulation 에서, GPT-3 는 

<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<span style='background-color: #dcffe4'> 초록색배경 </span>
