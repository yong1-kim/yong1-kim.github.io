---
layout: post
title:  "[EMNLP2023] TaskDiff: A Similarity Metric for Task-Oriented Conversations"
date:   2024-02-23 23:00:00 +0900
use_math: true
categories: [Dialogue, PLM]
---

[[pdf]](https://aclanthology.org/2023.emnlp-main.1009.pdf) &emsp;
[[github]](https://github.com/enokawa/taskdiff/tree/master)

**Ankita Bhaumik<sup>†</sup>, Praveen Venkateswaran<sup>∗</sup>, Yara Rizk<sup>∗</sup>, Vatche Isahagian<sup>∗</sup>**
<br><sup>†</sup> Rensselaer Polytechnic Institute, Troy, New York <sup>∗</sup> IBM Research &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/7f02c344-a494-4533-a52c-5a61d4954087)

# Abstract
- (**TOD metrics**) 많은 similarity metric 들이 제안되었 지만, task-oriented conversation 의 unique 한 특성을 알아내는 metric 에 대한 연구는 많이 진행되지 않았다.
- (<span style='color:green;font-weight:bold'> TaskDiff </span>) 이에 저자들은 *TaskDiff* 라는 conversational similarity metric 을 제안한다. TaskDiff는 utterances, intents, slots 와 같은 다양한 dialogue component 를 활용하여 그 distribution 을 통해 optimal transport 를 활용하여 계산된다.
- (**Experiments**) 다양한 벤치마크에서 TaskDiff 가 superior performance 와 robustness 를 보인다.

## 1. Introduction

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/9df17141-a180-4c2b-97a3-ba8ca055f74a)

<span style='color:green;font-weight:bold'> ▶ A key aspect of conversational analytics  </span>
<br>
대화(conversation)에 대한 연구는 LLM 의 등장으로 가속화되었고, ChatGPT 나 LLaMA2 등을 활용한 assistant 들도 많이 등장하였다. 이것들을 통해 user-experience 가 develop 될 수 있다.
그러나, 여러 assistant 간에 누가 더 나은지를 측정하는 metric 은 연구가 충분히 이뤄지지 않는다.

<span style='color:green;font-weight:bold'> ▶ Textual similarity of Dialogue </span>
<br>
Document 나 social media, transcript 등의 textual source 에 대한 similarity 측정은 이미 많은 연구가 이뤄졌고, 꽤 좋은 성능을 보여주고 있다.
이러한 것 연구에는 Word2Vec, GloV2, Universal Sentence Encoder 등의 연국 ㅏ포함된다.

그러나, task-oriented conversation 은 기존의 metric 들의 적용에 여러 challenge 가 존재한다.
우선, TOD 는 distinct component (e.g. intents, slots, utterances) 를 포함하고 있어, similiarty 와 overlap 에 impact 가 될 수 있다. 예를 들면, user 둘은 다른 objective (e.g. booking travel vs. product returns) 를 가지고 있을 수 있지만, 같은 intent 를 가지고 있을 수 있고, 다른 slot info 를 원할 ㅅ수 있다.
두 번째로, information 이 multiple conversation turn에 걸쳐 제공된다는 점이 metric 으로의 어려움을 증가시킨다.
마지막으로, 같은 task 의 set 들도 여러 user utterance 들로 표현이 될 수 있으며, 이것들은 choice of phrasing, order of sentences, use of colloquialism 등을 포함할 수 있다.

따라서,  <span style='background-color: #ffdce0'> distance based similairty of utterance embedding 에 의존하는 것은 매우 나쁜 성능을 미친다. </span>

<span style='color:green;font-weight:bold'>  ▶ TaskDiff </span>
<br>
이에 저자들은 *TaskDiff* 라는 novel similarity metric designed for TOD 를 제안한다.
위의 그림처럼, 여러 user 들은 같은 대화를 하지만, re-ordered task 와 paraphrased utterance 등을 통해 바뀔 수 있는데, 기존의 방법들은 (SBERT, ConvED, HOTT 등)은 틀리거나 robust 하지 않은 것을 볼 수 있다.

<span style='background-color: #dcffe4'> Ideal Metric to measure conversational similarity 는 conversation 의 overall goal 을 반드시 맞춰야 한다는 것이다. </span>
위의 그림 역시 overall goal 은 세 대화 모두 동일하다.
TaskDiff 는 converation 을 distribution 으로 표현한 다음, optimal transport 와 결합하여 similarity 를 측정한다.
여러가지 benchmark 에 taskdiff 를 측정한 결과 높은 performance 와 강한 robustness 를 보인다.

## 2. Task-Oriented Conversation Similarity





<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
