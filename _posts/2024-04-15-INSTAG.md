---
layout: post
title: "[ICLR2024] #INSTAG: INSTRUCTION TAGGING FOR ANALYZING SUPERVISED FINE-TUNING OF LARGE LANGUAGE MODELS"
date: 2024-04-15 13:20:00 +0900
use_math: true
categories: [LLM, PLM]
---

[[pdf]](https://openreview.net/attachment?id=pszewhybU9&name=pdf) &emsp;
[[github]](https://github.com/OFA-Sys/InsTag)

**Keming Lu∗& Hongyi Yuan∗& Zheng Yuan & Runji Lin & Junyang Lin & Chuanqi Tan & Chang Zhou & Jingren Zhou**
<br> Alibaba DAMO Academy &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/822daeff-5c6b-4eff-8889-308c7a2ecc17)

## Abstract
- (<span style='background-color: #dcffe4'> Lack of diversity in instruction-following data </span>) LLM 을 supervised fine-tuning (SFT) 을 통해 instruction 을 학습시킬 수 있다. 이를 위해 좋은(good) instruction-following dataset 이 필요한데, 현재 diversity 와 complexity 의 측면에서 데이터가 희박하고 분석이 부족하다.
- (<span style='color:green;font-weight:bold'> INSTAG </span>) 이제 저자들은 INSTAG 라는 open-set instruction tagging method 를 제안한다. 이는 tag 를 통해 human instruction 의 semantic 과 intention 을 부여하여, instruction diversity 와 complexity 를 정량적으로 분석할 수 있게한다.
- (**Data sampling procedure**) INSTAG 의 diverse and complex instruction 을 통해 LLM 학습에 효과를 본 것을 토대로, data sampling procedure 를 통해 6K 개의 sample 을 선별한다.
- (**TAGLM**) INSTAG 를 학습한 모델인 TAGLM 이 MT-bench 에서 다른 open-source model 을 압도한다.

## 1. Introduction

<span style='color:green;font-weight:bold'> ▶ Fine-tuning LLMs </span>
<br> 
LLM 을 finetuning 하는 것은 LLM 으로 하여금 Human preference 에 align 시키고 human intention 을 recognize 하게끔 만들어준다.
이러한 finetuning 방법에는 Supervised Fine-tuning (SFT)([[1-Alpaca]](https://crfm.stanford.edu/2023/03/13/alpaca.html),[[2-Vicuna]](https://arxiv.org/abs/2306.05685)), rejection sampling([[3-RRHF]](https://arxiv.org/pdf/2304.05302.pdf),[[4-PRO]](https://arxiv.org/pdf/2306.17492.pdf),[[5-DPO]](https://arxiv.org/pdf/2305.18290.pdf)), RLHF([[6-RLHF]](https://arxiv.org/pdf/2204.05862.pdf),[[7-InstructGPT]](https://arxiv.org/pdf/2203.02155.pdf),[[8-LLama2]](https://arxiv.org/abs/2307.09288)) 등이 존재한다.

<span style='color:green;font-weight:bold'> ▶ SFT for LLMs </span>
<br> 
<span style='background-color: #dcffe4'> 
그 중에서도 SFT for alignment 는 보통 multi-turn utterance manner 로 형성되며, 각 turn 은 human query 와 human preference 에 well-aligned 된 reponse 로 구성된다.
 </span>
이러한 SFT 데이터셋들은 보통 crowd-sourcing data 를 활용하거나, 다른 LLM 으로 부터 distilling 하는 방법을 통해 모인다.

최근 여러 연구들에서 이러한 alignment 를 위한 SFT training data 들은 반드시 diverse/complex/covering various domains/tasks/semantics 등의 특징을 지녀야 한다고 주장한다. ([[9-WizardLM]](https://arxiv.org/abs/2304.12244),[[10-Orca]](https://arxiv.org/abs/2306.02707),[[11-TULU]](https://arxiv.org/pdf/2306.04751.pdf)) 
<span style='background-color: #dcffe4'> 이러한 diversity 와 complexity 는 주로 query formation 에 의해 결정된다.
 </span>
다양한 연구에서 SFT-aligned LLM 의 성능을 끌어올리기 위하여, query 의 diversity 와 complexity 를 발전시키기 위해 방법론들을 제안하였지만, <span style='background-color: #ffdce0'> 어떠한 연구에서도 diversity 와 complexity 를 정량적으로 측정하려는 연구는 없었다. </span>

<span style='color:green;font-weight:bold'> ▶ INSTAG </span>
<br> 
이를 위해 저자들은 SFT dataset 들의 sample 을 categorize 하는 tagging system 을 제안한다.
다재다능한 task 를 풀기 위해서는 다재다능한 tagging system 이 필요하지만, manual 한 fine-grained tagging system 은 large scale dataset 에 적용하기 너무 어렵다.
<span style='background-color: #dcffe4'> 
이에 저자들은 ChatGPT 를 활용하는 INSTAG 라는 automatic Instruction Tagging method 를 제안한다.
</span>
ChatGPT 의 prompting 에 심혈을 기울여, systematic tagging system 을 구성하고, INSTAG 를 SFT dataset 에 적용하여, human query 에 semantic 과 intention 을 잘 tagging 할 수 있음을 검증한다.
이 과정에서 diversity 와 complexity 의 측면에서 정량적으로 query distribution 을 측정할 수 있는 세세한 분석을 제공한다.
당연하게도, 이 분석과정에서 더 diverse 하고 더 complex 한 query 가 SFT 를 통해 alignment performance 를 향상시키는 것을 보인다.
이 검증에 따라, INSTAG 를 data selector 로 활용하여, compexlity-first diverse ampling method 를 구성하여 데이터를 모으고, 이 데이터를 학습시킨 LLM 이 MT-Bench 에서 좋은 성능을 보인다.

<span style='color:green;font-weight:bold'> ▶ Contributions </span>
<br> 
논문의 contribution 을 정리하면 아래와 같다.
- (1) Instruction diversity/complexity metric 으로써의 open-set fine-grained intention tagging 방법인 INSTAG 를 제안한다.
- (2) Query divserity 와 complexity 에 대한 분석으로 insight 를 제공한다.
- (3) INSTAG 를 통한 data selection 을 통해 좋은 데이터를 모으고, 이를 학습하여 LLaMA 기반의 TAGLM 을 제안하여, MT-BENCH 에서 좋은 성능을 보인다.

## 2. Related Works
<span style='color:green;font-weight:bold'> Data for Human Alignment </span>
<br>
**It has been highlighted that the performance of aligned LLMs is affected by the quality of the SFT data.**
이러한 Data quality 은 response-level([[11]](https://arxiv.org/abs/2304.03277),[[12]](https://arxiv.org/abs/2306.05685)) 에서 존재하거나, task difficulty([[13]](https://arxiv.org/abs/2306.02707)), query complexity([[14]](https://arxiv.org/abs/2304.12244)), semantic diversity([[15]](https://arxiv.org/abs/2305.14233),[[16]](https://crfm.stanford.edu/2023/03/13/alpaca.html)), 그리고 sample amount scale([[17]](https://arxiv.org/abs/2305.11206)) 에 존재할 수 있다.

Self-Instruct, Evol-Instruct 등도 diversity 와 complexity 를 증가시킬 수 있는 방법이다.
Orca 에서는 FLAN 의 response 와 query 를 기존의 LLM 을 활용하여 rewrite 하여 NLP task 를 푸는데 성능 향상을 가져왔다. 
[UltraChat](https://arxiv.org/pdf/2305.14233.pdf) 에서는 manual 하게 design 한 다양한 anchor concept 과 entity 를 통해 ChatGPT 와의 대화를 통해 multi-turn data 를 생성한다.
OpenChat 과 Vicuna 는 SharGPT 를 통해 GPT-4 의 user log 를 학습하여 cutting-edge instruction following 능력을 갖춘 ChatLLM 모델이다.
OpenChat 에서는 ShareGPT 를 통한 user log 로부터 query 를 활용하는 것은 instruction following 능력을 향상시킨다는 결과가 있다.
Lima 에서는 적은 양의 high-quality data 만으로도 human alignment 를 잘 학습시킬 수 있음을 보인다.

<span style='background-color: #ffdce0'> 
이렇듯 human intention 을 LLM 에 학습시키기 위해 diverse and complex SFT data 를 활용하는 연구가 많이 존재하지만, 여전히 query 의 diversity 와 complexity 를 정량적으로 측정하고 논의하는 연구는 부족하다.
 </span>
 이 연구에서는 ChatGPT 의 퍼포먼스를 바탕으로 automatic tagging system 을 제안하여 training data 의 diversity 와 complexity 를 정량적으로 제안한다.

 
## 3. INSTAG
# 3.1. OPEN-SET FINE-GRAINED TAGGING

# 3.2. TAG NORMALIZATION

# 3.3. QUALITY EVALUATION

# 3.4. PRELIMINARY ANALYSIS

## 4. INSTAG FOR DATA SELECTION
# 4.1. EXPERIMENTAL SETUP

# 4.2. RESULTS

# 4.3. DECOUPLED ANALYSIS

## 5. INSTAGGER: LOCAL TAGGER BY DISTILLATION

## 6. CONCLUSION
```
In this paper, we introduced INSTAG, an open-set tagging method leveraging the instructionfollowing ability of ChatGPT for SFT data analysis. We apply INSTAG on open-source SFT datasets, showing diverse and complex data leads to better alignment performance. We designed a complexity-first diverse sampling method to select 6K samples, and TAGLM fine-tuned on this selected dataset outperforms other open-source models aligned with considerably more data. Moreover, further decoupled analyses revealed that model performance increases with fine-tuning on more diverse and complex SFT data, respectively. In summary, our proposed INSTAG provides a novel aspect for a deeper understanding of query distribution in the alignment of LLMs. It has robust potential to be extended to more applications beyond the data selection shown in this work, such as creating comprehensive evaluations and tag-based self-instruct.
```

<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
