---
layout: post
title: "[ICLR2024] #INSTAG: INSTRUCTION TAGGING FOR ANALYZING SUPERVISED FINE-TUNING OF LARGE LANGUAGE MODELS"
date: 2024-04-15 13:20:00 +0900
use_math: true
categories: [LLM, PLM]
---

[[pdf]](https://openreview.net/attachment?id=pszewhybU9&name=pdf) &emsp;
[[github]](https://github.com/OFA-Sys/InsTag)

**Keming Lu∗& Hongyi Yuan∗& Zheng Yuan & Runji Lin & Junyang Lin & Chuanqi Tan & Chang Zhou & Jingren Zhou**
<br> Alibaba DAMO Academy &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/822daeff-5c6b-4eff-8889-308c7a2ecc17)

## Abstract
- (<span style='background-color: #dcffe4'> Lack of diversity in instruction-following data </span>) LLM 을 supervised fine-tuning (SFT) 을 통해 instruction 을 학습시킬 수 있다. 이를 위해 좋은(good) instruction-following dataset 이 필요한데, 현재 diversity 와 complexity 의 측면에서 데이터가 희박하고 분석이 부족하다.
- (<span style='color:green;font-weight:bold'> INSTAG </span>) 이제 저자들은 INSTAG 라는 open-set instruction tagging method 를 제안한다. 이는 tag 를 통해 human instruction 의 semantic 과 intention 을 부여하여, instruction diversity 와 complexity 를 정량적으로 분석할 수 있게한다.
- (**Data sampling procedure**) INSTAG 의 diverse and complex instruction 을 통해 LLM 학습에 효과를 본 것을 토대로, data sampling procedure 를 통해 6K 개의 sample 을 선별한다.
- (**TAGLM**) INSTAG 를 학습한 모델인 TAGLM 이 MT-bench 에서 다른 open-source model 을 압도한다.

## 1. Introduction

<span style='color:green;font-weight:bold'> ▶ Fine-tuning LLMs </span>
<br> 
LLM 을 finetuning 하는 것은 LLM 으로 하여금 Human preference 에 align 시키고 human intention 을 recognize 하게끔 만들어준다.
이러한 finetuning 방법에는 Supervised Fine-tuning (SFT)([[1-Alpaca]](https://crfm.stanford.edu/2023/03/13/alpaca.html),[[2-Vicuna]](https://arxiv.org/abs/2306.05685)), rejection sampling([[3-RRHF]](https://arxiv.org/pdf/2304.05302.pdf),[[4-PRO]](https://arxiv.org/pdf/2306.17492.pdf),[[5-DPO]](https://arxiv.org/pdf/2305.18290.pdf)), RLHF([[6-RLHF]](https://arxiv.org/pdf/2204.05862.pdf),[[7-InstructGPT]](https://arxiv.org/pdf/2203.02155.pdf),[[8-LLama2]](https://arxiv.org/abs/2307.09288)) 등이 존재한다.

<span style='color:green;font-weight:bold'> ▶ SFT for LLMs </span>
<br> 
<span style='background-color: #dcffe4'> 
그 중에서도 SFT for alignment 는 보통 multi-turn utterance manner 로 형성되며, 각 turn 은 human query 와 human preference 에 well-aligned 된 reponse 로 구성된다.
 </span>
이러한 SFT 데이터셋들은 보통 crowd-sourcing data 를 활용하거나, 다른 LLM 으로 부터 distilling 하는 방법을 통해 모인다.

최근 여러 연구들에서 이러한 alignment 를 위한 SFT training data 들은 반드시 diverse/complex/covering various domains/tasks/semantics 등의 특징을 지녀야 한다고 주장한다. ([[9-WizardLM]](https://arxiv.org/abs/2304.12244),[[10-Orca]](https://arxiv.org/abs/2306.02707),[[11-TULU]](https://arxiv.org/pdf/2306.04751.pdf)) 
<span style='background-color: #dcffe4'> 이러한 diversity 와 complexity 는 주로 query formation 에 의해 결정된다.
 </span>
다양한 연구에서 SFT-aligned LLM 의 성능을 끌어올리기 위하여, query 의 diversity 와 complexity 를 발전시키기 위해 방법론들을 제안하였지만, <span style='background-color: #ffdce0'> 어떠한 연구에서도 diversity 와 complexity 를 정량적으로 측정하려는 연구는 없었다. </span>

<span style='color:green;font-weight:bold'> ▶ INSTAG </span>
<br> 
이를 위해 저자들은 SFT dataset 들의 sample 을 categorize 하는 tagging system 을 제안한다.
다재다능한 task 를 풀기 위해서는 다재다능한 tagging system 이 필요하지만, manual 한 fine-grained tagging system 은 large scale dataset 에 적용하기 너무 어렵다.
<span style='background-color: #dcffe4'> 
이에 저자들은 ChatGPT 를 활용하는 INSTAG 라는 automatic Instruction Tagging method 를 제안한다.
</span>
ChatGPT 의 prompting 에 심혈을 기울여, systematic tagging system 을 구성하고, INSTAG 를 SFT dataset 에 적용하여, human query 에 semantic 과 intention 을 잘 tagging 할 수 있음을 검증한다.
이 과정에서 diversity 와 complexity 의 측면에서 정량적으로 query distribution 을 측정할 수 있는 세세한 분석을 제공한다.
당연하게도, 이 분석과정에서 더 diverse 하고 더 complex 한 query 가 SFT 를 통해 alignment performance 를 향상시키는 것을 보인다.
이 검증에 따라, INSTAG 를 data selector 로 활용하여, compexlity-first diverse ampling method 를 구성하여 데이터를 모으고, 이 데이터를 학습시킨 LLM 이 MT-Bench 에서 좋은 성능을 보인다.

<span style='color:green;font-weight:bold'> ▶ Contributions </span>
<br> 
논문의 contribution 을 정리하면 아래와 같다.
- (1) Instruction diversity/complexity metric 으로써의 open-set fine-grained intention tagging 방법인 INSTAG 를 제안한다.
- (2) Query divserity 와 complexity 에 대한 분석으로 insight 를 제공한다.
- (3) INSTAG 를 통한 data selection 을 통해 좋은 데이터를 모으고, 이를 학습하여 LLaMA 기반의 TAGLM 을 제안하여, MT-BENCH 에서 좋은 성능을 보인다.

## 2. Related Works
<span style='color:green;font-weight:bold'> Data for Human Alignment </span>
<br>
**It has been highlighted that the performance of aligned LLMs is affected by the quality of the SFT data.**
이러한 Data quality 은 response-level([[11]](https://arxiv.org/abs/2304.03277),[[12]](https://arxiv.org/abs/2306.05685)) 에서 존재하거나, task difficulty([[13]](https://arxiv.org/abs/2306.02707)), query complexity([[14]](https://arxiv.org/abs/2304.12244)), semantic diversity([[15]](https://arxiv.org/abs/2305.14233),[[16]](https://crfm.stanford.edu/2023/03/13/alpaca.html)), 그리고 sample amount scale([[17]](https://arxiv.org/abs/2305.11206)) 에 존재할 수 있다.

Self-Instruct, Evol-Instruct 등도 diversity 와 complexity 를 증가시킬 수 있는 방법이다.
Orca 에서는 FLAN 의 response 와 query 를 기존의 LLM 을 활용하여 rewrite 하여 NLP task 를 푸는데 성능 향상을 가져왔다. 
[UltraChat](https://arxiv.org/pdf/2305.14233.pdf) 에서는 manual 하게 design 한 다양한 anchor concept 과 entity 를 통해 ChatGPT 와의 대화를 통해 multi-turn data 를 생성한다.
OpenChat 과 Vicuna 는 SharGPT 를 통해 GPT-4 의 user log 를 학습하여 cutting-edge instruction following 능력을 갖춘 ChatLLM 모델이다.
OpenChat 에서는 ShareGPT 를 통한 user log 로부터 query 를 활용하는 것은 instruction following 능력을 향상시킨다는 결과가 있다.
Lima 에서는 적은 양의 high-quality data 만으로도 human alignment 를 잘 학습시킬 수 있음을 보인다.

<span style='background-color: #ffdce0'> 
이렇듯 human intention 을 LLM 에 학습시키기 위해 diverse and complex SFT data 를 활용하는 연구가 많이 존재하지만, 여전히 query 의 diversity 와 complexity 를 정량적으로 측정하고 논의하는 연구는 부족하다.
 </span>
 이 연구에서는 ChatGPT 의 퍼포먼스를 바탕으로 automatic tagging system 을 제안하여 training data 의 diversity 와 complexity 를 정량적으로 제안한다.

 
## 3. INSTAG

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/fa4e91a3-119e-420d-9b8d-f9bb9c6ec6ed)

# 3.1. OPEN-SET FINE-GRAINED TAGGING

최근 Chatbot 에 prompt 로 활용이 되는 Instruction 은 복잡하고 multifacted 되어 있는 user intention 의 표현이다.
위의 Figure1 의 ShareGPT 의 예시(_Write flask routes for blog posts that implement CRUD. Use flask-sqlalchemy. The incoming and outgoing data should be in JSON. Use appropriate error handling and return status codes_)와 같이, user intention 은 복잡하기 때문에 fine-grained tag 가 필요하다.
그러나 이러한 fine-grained tag 를 얻는 것은 어려운데 annotation 과 normalization 이 어렵기 때문이다.
이에 저자들은 ChatGPT 를 활용한 automatic tagging system 과 normalization technique 을 제안한다.
아래의 prompt 를 ChatGPT 에 부여하여 few-shot ICL 을 통해 tagging 을 한다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/ed4cc372-efde-46c5-b01f-72ec35af6fc3)

# 3.2. TAG NORMALIZATION
위의 방법대로 ChatGPT 가 출력한 original raw tag 는 12,000 개로 다양한 fine-grained tag 를 생성할 수 있음을 알 수 있지만 너무 noise 하다는 단점이 있다.
예를 들어, 아래의 Table 1 과 같은 inonsistency 들을 포함할 수 있다.

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/86ee1471-e467-4844-a915-c29eeb81e435)

**Lexical Noise** 는 ChatGPT 의 instability 로 인해 발생하는 것으로 post-processing 으로 간단히 해결 가능하다.
**Uncontrolled Granularity** 는 너무 specific 한 tag 를 생성하는 경우이고, **Spurious Corrletaion** 은 ChatGPT 의 bias 에 의해 발생한다.

따라서 저자들은 위의 Figure 1 과 같이, 다음의 네 가지 normalization procedure 를 통해 raw tagging 을 cleaning 한다.
- **Frequency Filtering** : $\alpha$ time 미만의 long-tail tag 는 filter-out 한다.
- **Rule Aggregation** : Lexcial noise 해결을 위해, 모두 소문자화하고 특수문자를 공백처리하는 post processing 을 제거한다.
- **Semantic Aggregation** : PhraseBERT 혹은 DensePhrase 같은 text embedding model 을 활용하여 tag 의 semantic 을 얻고, DBSCAN 알고리즘을 활용하여 tag 를 cluster 하여 대표(representative) tag 로 뭉친다.
- **Association Aggregation** : Mathematics 나 coding query 에서 주로 발생하는 atomic tag 문제 해결을 위해, FP-Growth 알고리즘 을 적용하여 association 통합을 한다. 

저자들은 INSTAG 방법을 **SHAREGPT, OPENChat, UltraCHAT, Alpaca, WizardLM, FLAN, Dolly, OAssist, Unnatural, Lima, Math Collections, Code Collections** 등 17개 데이터셋에 적용한다. 
$\alpha$ 는 20 으로 한 뒤 나머지 aggregation 방법을 적용한 결과, 1,772 개가 남았다. 

# 3.3. QUALITY EVALUATION
GPT-4 와 human annotator  들을 활용하여 tagging quality 를 분석한다. 
분석 메트릭은 다음의 두 가지이다.
- **Precision** : Query-Tag 사이의 일치도를 본다.
- **Consistency** : Tag 와 그 tag 에 속하는 randomly selected instruction 사이의 일치도를 본다.

결과는 아래와 같다. 

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/1de78de0-0d43-41f6-9561-f141e2cc8e68)

※ 자세한 결과분석은 논문 참고

# 3.4. PRELIMINARY ANALYSIS

## 4. INSTAG FOR DATA SELECTION
# 4.1. EXPERIMENTAL SETUP

# 4.2. RESULTS

# 4.3. DECOUPLED ANALYSIS

## 5. INSTAGGER: LOCAL TAGGER BY DISTILLATION

## 6. CONCLUSION
```
In this paper, we introduced INSTAG, an open-set tagging method leveraging the instructionfollowing ability of ChatGPT for SFT data analysis. We apply INSTAG on open-source SFT datasets, showing diverse and complex data leads to better alignment performance. We designed a complexity-first diverse sampling method to select 6K samples, and TAGLM fine-tuned on this selected dataset outperforms other open-source models aligned with considerably more data. Moreover, further decoupled analyses revealed that model performance increases with fine-tuning on more diverse and complex SFT data, respectively. In summary, our proposed INSTAG provides a novel aspect for a deeper understanding of query distribution in the alignment of LLMs. It has robust potential to be extended to more applications beyond the data selection shown in this work, such as creating comprehensive evaluations and tag-based self-instruct.
```

<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>
<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
