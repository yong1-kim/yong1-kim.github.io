---
layout: post
title:  "[ICLR2024] SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
date:   2024-02-19 20:27:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2310.11511.pdf) &emsp;
[[openreview]](https://openreview.net/forum?id=hSyW5go0v8) &emsp;
[[github]](https://github.com/AkariAsai/self-rag)

**Akari Asai<sup>†</sup>, Zeqiu Wu<sup>†</sup>, Yizhong Wang<sup>†§</sup>, Avirup Sil<sup>‡</sup>, Hannaneh Hajishirzi<sup>†§</sup>**
<br><sup>†</sup> University of Washington <sup>§</sup> Allen Institute for AI <sup>‡</sup> IBM Research AI &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/3f85785b-b3b0-461a-8397-57285fbb97ce)

## Abstract
- (**Hallucination and RAG**) LLM 의 강력한 성능에도 Hallucination (Factual inconsinstency) 문제는 여전히 발생하고, Retrieval-Augmented Generation (RAG) 을 기반으로한 LM 모델이 이러한 issue 를 잘 다룬다.
- (**Unrelevant retrieval probelm**) 그러나, retrieval 자체가 necessary 하지 않거나, passage 가 relevant 하지 않은 경우에는 이러한 Retireval Augment 방법 자체가 response generation 에 unhelpful 할 수 있다.
- (<span style='color:green;font-weight:bold'> Self-RAG </span>) 이에 본 연구에서는 **Self-Reflective Retrieval-Augmented Generation (Self-RAG)** 방법을 제안한다. 이는 하나의 LM 이 <span style='background-color: #dcffe4'> 
 (1) passage 를 on-demand 로 retrieve 해오고, 이를 통해 (2) generate 한 이후, (3) refelection token 을 통해 retrieved passage 와 own generation 을 reflect 한다. </span>
- (**Controllability**) inference 과정에서 다양한 task 요구에 맞춰 reflection token 을 조절할 수 있다.
- (**Experiment**) 실험 결과 7B, 13B 모델이 state-of-the-art RALM 을 능가하는 성능을 보였고, Open-domain QA 에서 ChatGPT 와 retrieval-augmented LLaMa2-chat 의 성능을 뛰어넘었다. 그리고 Long-form generation 에서의 factuality accuracy 도 매우 높다.

## 1. Introduction





<span style='color:green;font-weight:bold'> 초록색볼드체 </span>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
