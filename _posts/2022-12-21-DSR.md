---
layout: post
title:  "[NAACL2022] Database Search Results Disambiguation for Task-Oriented Dialog Systems"
date:   2022-12-21 09:46:00 +0900
use_math: true
categories: [Dialogue]
---
[[pdf]](https://arxiv.org/pdf/2112.08351.pdf) &emsp;
[[papers with code]](https://paperswithcode.com/paper/database-search-results-disambiguation-for)

**Kun Qian<sup>†</sup>, Satwik Kottur<sup>‡</sup>, Ahmad Beirami<sup>‡</sup>, Shahin Shayandeh<sup>‡</sup>, Paul Crook<sup>‡</sup>, Alborz Geramifard<sup>‡</sup>, Zhou Yu<sup>†</sup>, Chinnadhurai Sankar<sup>‡</sup>**
<br><sup>†</sup> Columbia University, <sup>‡</sup> Meta AI  &emsp;

![image](https://user-images.githubusercontent.com/42200027/208795566-2cb970dc-656d-4d30-8652-c272a4a6b43a.png)

# Abstract
- (Motivation) 현재 Task Oriented Dialogue (TOD) 에서 여러 database search result 에 대해 하나의 결과만을 제시함.
- (New Task) 이에 저자들은 두 가지 database search result 를 제시하는 *Database Search Result (DSR) Disambiguation* 이라는 새로운 task 를 제시함.
- (Solution) Pre-defined grammar 를 이용하여 turn 을 synthetically generate 하고, human paraphrasing 을 이용해 dataset 을 구성
- (Experiment) 만들어진 데이터셋으로 Augmentation 한 결과, 그렇지 않은 경우보다 multiple database search result 를 disambiguation 하는 문장에 대해 좋은 성능을 보였고, 제시하는 연구를 통해 user exprience 를 enhancing 하는 것을 확인함. 

# Introduction
![image](https://user-images.githubusercontent.com/42200027/208794481-bc134ba5-f10a-44a6-a309-4925d3a79c66.png)
Task-Oriented Dialogue System (TOD) 은 Siri, Google Assistant 같은 virutal assistant 를 위하여 활발히 연구가 진행되고 있다.
이들은 user 와 대화를 이어가며 constraint 를 좁혀가다가, database search result 를 통해 entity 를 제시한다.
그러나, 위의 그림과 같이 현존하는 TOD System 들은 database search result 가 여러 개일 때도, 단 하나의 entity 만을 제시한다.
이러한 것을 저자들은 database search result ambiguity (DSR-ambiguity) 라고 정의한다.
<br>
이러한 ambiguity 를 해소하는 방법에는 두 개의 step 이 필요하다.
첫 번째는 clarification question 을 질문하는 step, 그리고 두 번째는 user의 corresponding answer 를 이해하는 step 이다.
첫 번째에 관한 연구는 많이 이뤄지고 있지만, 두 번째 asnwer/intent 를 understanding 하는 연구는 거의 이뤄지지 않고 있다.
이에 저자들은 [MultiWoz ](https://aclanthology.org/D18-1547/) 와 [SGD](https://arxiv.org/abs/1909.05855) 를 augmentation 하여 두 번째 step 에 대한 성능 향상을 도모한다.
<br>
MutliWoz 와 SGD 는 많은 State-of-the-Art TOD system 에서 사용되는 dataset 들이지만, 66% 에 해당하는 dialogue 에서 database search result ambiguity 가 발생한다.
그러나 모든 대화에서 여러 db search result 중 하나를 pick 하여 제시한다.
모든 result 를 제시할 필요는 없지만 2 개에서 3 개의 option 을 제시하는 것은 user 의 engagment 를 크게 도와준다.
저자들은 disambiguation turn 을 포함하는 [SIMMC 2.0](https://arxiv.org/abs/2104.08667) dataset 에서 template 을 추출하고, MultiWoz 와 SGD 에서 database 를 추출하여, disambiguation 에 해당하는 1-turn dialogue dataset 을 생성하여 실험한다.
이후, reality 로의 application 을 위하여, 이 것을 MultiWoz 와 SGD 에 augmentation 한 후, model 에 학습시킨다.
<br>
저자들이 정리한 contribution 은 아래와 같다.
1. We propose <span style='background-color: #dcffe4'> Database Search Result Disambiguation </span>, a new dialog task focused on understanding the user’s needs through clarification questions.
2. We provide a generic framework for augmenting disambiguation turns, and apply this framework to <span style='color:green;font-weight:bold'> augment the two most popular task-oriented dialog datasets </span> with disambiguation cases. We also conduct <span style='color:green;font-weight:bold'> human paraphrasing </span> for the augmented utterances in test sets.
3. We create a benchmark for the new task with pre-trained GPT2 model. The results show that our augmented dataset enhances the model’s disambiguation ability, while maintaining the performance on the original tasks

# Task Formulation
![image](https://user-images.githubusercontent.com/42200027/208797635-bde6030d-23fb-4fdf-a219-fe02c229c2de.png)
저자들은 <span style='background-color: #dcffe4'> New task ; disambiguation in dialog database search result </span>  를 제시한다.
위의 그림과 같이, dialog context $c$ 와 optional result 를 포함하는 system response $s$ 그리고 user uttr $u$ 에 대하여, 
<span style='color:green;font-weight:bold'> task 의 target 은 user 에 의해 선택된 result 에서 entity 를 추출하는 것 </span>  이다.

# Dataset
MultiWoz 와 SGD 는 disambiguation task 를 위한 case 들을 포함하고 있지 않기 때문에, 세 가지 step 을 통해 두 데이터셋을 augmentation 한다.
<br>
<span style='color:green;font-weight:bold'> 3.1 Synthesizing Single-Turn Dialog </span> <br><br>
![image](https://user-images.githubusercontent.com/42200027/208798359-f56a07b8-3653-4161-b533-60f912ec68f5.png)
위의 그림과 같이, synthetic 한 single-turn dialog 를 우선 생성하여, 모델로 하여금 disambiguation turn 을 학습하게 한다.
앞으로, 이러한 형태로 disambiguation turn 이 다뤄진다.
System reponse $s$ 에는 파란 색으로 여러 가지 option 이 제시되며, user utterance $u$ 에서 빨간 색으로 선택한 result 의 entity 가 제시된다.
모델을 user utterance $u$ 에서 entity name 을 추출하는 것이 목적이다.
<br>
이러한 synthetic turn 을 만들기 위하여 SIMMC 2.0 dataset 에서 template 을 생성한다.
SIMMC 2.0 dataset 에는 *“do you mind being a bit more precise about which shoes you’re curious about, the red one or the blue one”* 와 같이 ambiguity 를 solve 하는 turn 이 존재한다.
저자들은 이 utterance 에서 domain-related token (ex "shoes", "the red one", "the blue one") 을 delexicalize 한 후, template 을 생성한다.
이후, template 으로부터 <span style='background-color: #dcffe4'> Context-free Grammar (CFG)  </span> 를 추출한 후, 이것을 통해 turn 을 생성한다.
CFG 의 결과물은 "SENT-> do you mind VERBING", 과 같다. 
<span style='color:green;font-weight:bold'> CFG 는 이론상 2 백만 개의 system utterance $s$ , 그리고 3 만개 이상의 user utterance $u$ 를 생성할 수 있어, diversity 가 보장된다. </span> 
그리고 MultiWoz 와 SGD 의 여러 domain 에서 entity 들을 추출한 후, CFG 에 삽입하여 synthetic turn 을 만들어낸다.
Natural 한 utterance 를 위하여 option 은 최대 5개 까지로 제한한다.
<br>
추가적으로 <span style='color:green;font-weight:bold'> user utterance $u$ 를 어렵게 만들기 위하여 </span>, **Positional Addressing, Partial Addressing, Addressing with Typo, Multiple Addressing, Addressing with Attributes** 5 가지 방법을 활용한다.

<br> 
<span style='color:green;font-weight:bold'> 3.2 Automatic Augmentation </span> <br>
3.1 에서의 single-turn 만 학습해서는 complete dialog 에서의 적용이 어렵다.
이에 저자들은 MultiWoz 와 SGD 에 disambiguation turn 을 추가하여 augmentation 한다.
<br>
![image](https://user-images.githubusercontent.com/42200027/208799883-e0e203d4-49a0-4b6e-bfd7-ceda821227ff.png)
<br>
위의 그림에서, 66.7% 의 turn 에서 ambiguity 가 발생하는 것을 볼 수 있다. 
SGD 와 MultiWoz 에서는 항상 db search 이후, 단 하나의 suggenstion 을 제시한다. 
그리고 suer side 에서는 simply accept 한 이후 대화가 진행된다.
이를 통해 dataset 속의 ambiguity 를 **avoid** 한다.
<br>
![image](https://user-images.githubusercontent.com/42200027/208800568-c20793a2-bd51-4a7a-9714-0931b9062cf1.png)
<br>
위의 그림과 같이, 3.1 에서의 CFG 와 MultiWoz/SGD 의 database 속의 slot-value 를 활용하여, system utterance $s$ 를 생성한다.
이후, user 의 utterance $u$ 에서 choice 를 하는 문장을 덧붙인 후, 이를 original dialog 에 concat 한다.
turn 이 바뀌지 않기 때문에, 대화가 변하지 않은 dialogue 에서의 effect 를 줄일 수 있다.
<br>
모든 domain 에서 이러한 ambiguity 가 발생하는 것은 아니다.
따라서 저자들은 MultiWoz 에서는 restaurant, hotel, 그리고 attraction 에 대해서 진행하고, SGD 에서는 45 개 service 중 24 개에 대해서만 진행하였다.
30% 정도의 dialogue 가 포함되었고, 2% 정도의 turn 이 수정되었다.
<br><br>
<span style='color:green;font-weight:bold'> 3.3 Human Paraphrasing </span>
<br>
CFG 를 통해 생성된 user utterance 는 부자연스러울 수 있다.
이에 저자들은 위의 그림과 같이 user utterance 에 대하여 human paraphrasing 을 진행한다.
<br>
![image](https://user-images.githubusercontent.com/42200027/208801139-75f425e7-40de-4db9-847b-9cda0357d558.png)
<br>
Human Paraphrasing 에 활용한 interface 는 위의 그림과 같다.

# Experiment
<br>
![image](https://user-images.githubusercontent.com/42200027/208802136-4eab194b-56fb-47d5-8d8a-3ac2bb5e8667.png)
<br>
Dataset : MultiWoz / SGD <br>
Evaluation : (1) Accuracy on whether the model can successfully predict the correct name entity, (2) Joint Goal Accuracy (JGA) as DST <br>
Model : GPT-2 
Experiment : Original/Augmented Data 에 학습한 후, Original/Augmented/Human paraphrased test set 에 test. <br>
Augmentation turn 이 단지 2% 에만 해당하기 때문에, 학습 시 이 turn 의 수 만큼인 SGD 에서 5 천개, MultiWoz 에서 3 천개의 single-turn 을 생성하여 학습시킨다.
이후, 결과표에서 "Syn 100%" 라고 나오는 것은, training turn 의 수만큼 single-turn 을 추가로 학습한 모델이다.

# Results and Analysis
<span style='color:green;font-weight:bold'> 5.1 Augmentation Helps Resolve Ambiguity </span><br>
![image](https://user-images.githubusercontent.com/42200027/208802514-0639bd5f-c8fd-4ea4-a584-ff73d875783f.png)
<br>
첫 번째 실험 결과는, <span style='background-color: #dcffe4'> 전체 test set 의 2% 에 해당하는, augmented turn 에 대해서, name entity prediction accuracy 를 측정한 결과 </span> 이다.
Test set 에서의 "original" column 과 "Autoaug" column 을 비교했을 때, Original training dataset 으로 training 한 결과는 0.556 -> 0.242 로 (SGD), 0.676 -> 0.488 (MultiWoz) 로 안좋아졌다.
이는 기존의 MultiWoz/SGD dataset 들이 disambiguition turn 을 거의 갖고 있지 않다는 가정을 검증하는 결과이다.
따라서 clarification question 에 대한 user 의 대답을 이해하지 못한다.
그러나 "AutoAug" Row 들에 대하여서는 0.242 -> 0.496 (SGD), 0.488 -> 0.744 (MultiWoz) 로 좋아지는 것을 확인할 수 있다.
이를 통해 aumgentation skill 로 모델이 dimabigution skill 을 배운다는 것을 알 수 있다.
Human paraphrased dataset 에서도 같은 결과를 확인할 수 있다.
<br>
![image](https://user-images.githubusercontent.com/42200027/208803375-a2ff7f5e-4fe2-4824-88bc-5dc7fea6bd5b.png)
<br>
2% 에 해당하는 Augmented turn 에 대해서가 아닌, 전체 test set 에 대한 결과는 위와 같다.
변하지 않는 turn 이 많기 때문에, 그 전의 결과처럼 dramatic 한 성능 변화는 볼 수 없지만, 확실히 augmentated data 를 학습했을 때 더 좋은 성능을 보이는 것을 알 수 있다.
<br>
Name entity prediction 에 더하여, DST 에서 사용하는 Joint Goal Accruacy (JGA) 를 측정한다.
![image](https://user-images.githubusercontent.com/42200027/208803627-b264cbdf-a452-4055-bb1e-811cfeec35f7.png)
![image](https://user-images.githubusercontent.com/42200027/208803654-08ec6b9d-649e-4e11-8e4e-f5589aeac260.png)
<br>
Table 6 는 augmented turn 에 대하여, table 3 는 전체 test set 에 대한 JGA 측정 결과이다.
두 결과에서 모두 "Aug + Syn100%" 가 가장 좋은 성능을 보인다. 저자들은 augmentation 방법이 disambiguation 해결 뿐 아니라 DST 에도 좋다고 본다.

<br>
<span style='color:green;font-weight:bold'> 5.2 Augmentation Brings No Harm </span>
<br>
저자들의 utlimate goal 은 <span style='color:green;font-weight:bold'> "expand end-to-end TOD with t he disambiguation skill" </span> 이다.
이러한 DSR disambiguation augmentation 방법이 original dialog 를 푸는데 harm 이 없음을 확인하기 위해 위의 실험들에서 "original test set" 에 대하여 학습을 진행한 것이다.
당연하게도, Original Training set 으로 학습하거나 Syn 5% 정도만을 추가 학습한 모델은 Original Test set 과 distribution 을 공유하므로 좋은 성능을 보인다.
반면, Augmented Data 로 학습한 모델 역시 Original Test set 에 대하여 마찬가지로 좋은 성능을 보인다. 경우에 따라서는 오히려 더 좋은 성능을 보인 경우도 있다.
따라서, Augmented Data 로의 학습이 original test set 에서의 harm 이 되지 않는다는 것을 검증한다.
<br>
<br>
<span style='color:green;font-weight:bold'> 5.3 Leveraging Augmented Turns </span>
<br>
![image](https://user-images.githubusercontent.com/42200027/208805018-4c2303f9-987a-40b8-8060-07773ab87985.png)
저자들은 그들의 dataset 들을 효율적으로 활용하기 위하여, SGD 와 MultiWoz 를 함께 배우는 실험 세팅을 제시한다.
SGD 와 MultiWoz 는 비슷한 domain 을 공유하기 때문에, 서로 도움이 될 여지가 있다.
따라서 그들은 우선 SGD 를 fine-tune 한 이후, MultiWoz 에 fine-tune 한다. (SGD_ori + Origin)
이 때, SGD 의 경우 augmented SGD training data 로도 fine-tune 한다. (SGD_aug + Origin)
이는 전체 turn 의 2% 만 augmentation 되어 있으므로, 이 turn 들을 upsample 하여 fully augmented SGD 에 대해서도 먼저 학습한 세팅을 추가한다. (Upsample)
Name Entity Accuracy 에서는 "Upsample + Syn" 이 가장 좋은 성능을 보였으며, JGA 에 대해서는 "Aug + Syn"  이 가장 좋은 성능을 보였다.
이는 너무 많은 disambiguation turn 을 학습하는 것이 original task 에 영향을 준 것으로 파악된다.
따라서, <span style='background-color: #dcffe4'> 가장 좋은 방법은 target dataset 에 대해 제안된 방법으로 Augmention 한 것과 Synthesized single-turn data 를 추가학습 ("Aug + Syn") 한 모델을 활용하는 것이다. </span>
<br>
그리고 "SGD_ori + Origin + Syn" 의 경우, MultiWoz 를 전혀 augmentation 하지 않았음에도 좋은 성능을 보인다.
따라서 <span style='color:green;font-weight:bold'> SGD 와 MultiWoz 외의 데이터셋 </span> 에 대하여서는 저자들이 추천하는 방법은 <span style='color:green;font-weight:bold'> MultiWoz 와 SGD 의 자신들의 augmented data 를 학습한 이후, original data 를 fine-tune 하고, Synthsized single-turn dataset 역시 학습하는 방법 </span> 을 추천한다. 

