---
layout: post
title:  "[Arxiv 2305] Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"
date:   2024-03-15 16:00:00 +0900
use_math: true
categories: [Retrieval, LLM, PLM]
---

[[pdf]](https://arxiv.org/pdf/2305.14739.pdf) &emsp;
[[github]](https://github.com/hongshi97/CAD)

**Weijia Shi<sup>1*</sup>, Xiaochuang Han<sup>1*</sup>, Mike Lewis<sup>2</sup>, Yulia Tsvetkov<sup>1</sup>, Luke Zettlemoyer<sup>1</sup>, Scott Yih<sup>2</sup>**
<br><sup>1</sup> University of Washington, Seattle, WA, <sup>2</sup> Meta AI  &emsp;

![image](https://github.com/yong1-kim/yong1-kim.github.io/assets/42200027/e91e8ba5-39d6-40a4-b0e9-fe9c8d7dd42f)

# Abstract
- (**Context-Aware Decoding**) LM 의 decoding 과정에서, context 를 사용할 때와 사용하지 않을때 (with and without) 의 차이점을 극대화시키는 contrastive output distribution 을 따르는 context-aware decoding (CAD) 방법론을 제안한다.
- (**Improving Faithfulness**) Context-aware decoding 방법으로 OPT, GPT, LLaMA, FLAN-T5 summarization task 에서 faithfulness 향상을 이뤄낸다.
- (<span style='color:green;font-weight:bold'> Resolving Knowledge Conflict </span>) 추가적으로, CAD 는 provided contxet 가 prior knowledge 와 충돌할 때, 그 conflict 를 해결하는데 효과적이라고 주장한다.

## 1. Introduction





<span style='color:green;font-weight:bold'> 초록색볼드체 </span>
<br>

<span style='background-color: #dcffe4'> 초록색배경 </span>
<span style='background-color: #ffdce0'> 빨간색배경 </span>
