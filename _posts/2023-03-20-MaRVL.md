---
layout: post
title:  "Visually Grounded Reasoning across Languages and Cultures"
date:   2023-03-20 13:32:00 +0900
use_math: true
categories: [Vision-and-Language]
---
[[pdf]](https://aclanthology.org/2021.emnlp-main.818.pdf) &emsp;
[[blog]](https://marvl-challenge.github.io/) &emsp;
[[github]](https://github.com/marvl-challenge/marvl-code) 

**Fanyou Liu<sup>*1</sup>, Emanuele Bugliarello<sup>*2</sup>, Edoardo Maria Ponti<sup>3,4</sup>, Siva Reddy<sup>3,4</sup>, Nigel Collier<sup>1</sup>, Desmond Elliott<sup>2</sup>**
<br><sup>1</sup> University of Cambridge, <sup>2</sup> University of Copenhagen, <sup>3</sup> Mila - Quebec AI institute, <sup>4</sup> McGill University  &emsp;

![image](https://user-images.githubusercontent.com/42200027/226248111-01c818d4-696f-450c-9b9a-9b15988e8510.png)

# Abstract
- (Motivation) ImageNet을 바탕으로 한 데이터셋과 인코더들은 대부분 영어 기반으로 되어 있어 북미나 서유럽에서 가져온 자료가 대부분이다.
- (Dataset) 이를 해결하기 위해, 인도네시아어, 중국어, 스와힐리어, 타밀어, 터키어와 같은 다양한 언어를 대상으로 새로운 프로토콜을 도입하여 <span style='color:green;font-weight:bold'> MaRVL </span> 이라는 새로운 다국어 데이터셋을 구성했다. 
- 이 데이터셋은 이미지 Pair에 대한 지역문화를 반영한 답변을 수집하였으며, 다양한 언어 간 전이 학습 결과를 평가했다.
- 이를 통해, 다국어 및 다문화 시스템 개발에 새로운 도전과 발전 가능성을 제시한다.

# Introduction
ImageNet 은 컴퓨터 비전 연구의 기초를 제공했다. 이 데이터셋은 WordNet의 개념에서 선택된 개념 계층을 기반으로 한다. 이 데이터셋을 기반으로 NLVR2, MS-COCO, Visual Genome과 같은 다른 데이터셋이 구축되었고, "ResNet"과 같은 시각 데이터를 전처리하는 데 사용되는 사전 학습된 Encoder 도 만들어졌다. <span style='background-color: #dcffe4'> ImageNet에 포함된 개념과 이미지가, 이것이 만들어진 영어권과 북미, 유럽 문화를 넘어서서 얼마나 적합한가? </span>  이들의 이상적인 분포를 정의하는 것은 어려울 수 있으며, 목적에 따라 다양할 수 있다. 그러나, 전 세계적인 대표성을 목표로 한다면, 이 데이터의 기원과 내용이 편향되어 있다는 증거가 있다. 이를 해결하기 위해, [Yang et al.](https://dl.acm.org/doi/10.1145/3351095.3375709)은 데이터에 개입하여 일부 범주를 필터링하고 재균형을 제안했다. 그러나, 원래 분포의 범위가 다양한 언어와 문화를 포괄하지 않는 한, 이것은 여전히 부족하다. 따라서, 다중 모달 기술의 글로벌 아웃리치를 확대하기 위해서는, 보다 근본적인 계층 구조의 개편이 필요하다. 사실, 가장 두드러진 개념과 그들의 prototypical 멤버들과 시각적 표현은 문화나 환경적 요인에 따라 달라질 수 있다. 이러한 변화는 언어별 리소스에서 개념을 (무작위로) 선택하거나 웹 쿼리에서 이미지를 자동으로 수집하는 데이터셋 생성의 일반적인 관행으로 인해 흐려질 수 있다.

저자는 이 연구에서, 기존의 프로토콜을 개선하여 다문화 및 다언어 데이터셋을 만드는 데 도움이 되는 편향을 완화했다. 특히, 원어민의 구성원들이 선정한 개념과 이미지를 선택하도록 했다. 인도네시아어, 스와힐리어, 타밀어, 터키어, 중국어 등 다언어와 다양한 문화에 초점을 맞추었으며, 원어민이 작성한 이미지 쌍을 비교하도록 요청하여 그라운드된 기술적 설명을 수집했다. 이를 통해 매칭 기반보다는 깊은 언어적 이해가 필요하며, 모달리티 정보 통합이 필요한 작업을 선택하였다. 이 연구에서 제시된 <span style='background-color: #dcffe4'> 'Multicultural Reasoning over Vision and Language (MaRVL)' </span> 데이터셋의 예시는 위의 그림에서 볼 수 있다.

저자는 최신 시각언어 모델(Liu et al., 2019; Chen et al., 2020)을 MaRVL 데이터셋에서 평가하였다. 이를 위해 제로샷 및 번역기를 사용한 다국어 전이 학습을 수행하였으나, 성능이 영어 데이터셋(NLVR2; Suhr et al., 2019)에 비해 현저히 떨어졌다는 결과를 얻었다. 이러한 실패 원인을 조사한 결과, MaRVL은 이미지, 언어의 다양성 및 개념의 도메인 변화로 인해 매우 어려워졌다는 것을 발견하였다. 따라서, 현재 기준으로 MaRVL 데이터셋은 기존 벤치마크 대비 최신 모델의 일반화 능력을 더 신뢰할 수 있는 추정치를 제공할 수 있으며, 데이터셋, 주석 지침, 코드 및 모델은 [marvl-challenge.github.io](https://github.com/marvl-challenge/marvl-challenge.github.io)에서 제공된다.

# Motivation

ILSRVC1K (ImageNet Large-Scale Visual Recogntion)는 컴퓨터 비전 분야에서의 중요한 평가 지표인데, 이는 ImageNet에서 추출한 1,000개의 개념을 기반으로 한다. 그러나 이러한 데이터셋이 다양한 언어와 문화를 대표할 수 있는지에 대한 의문이 제기되어, 개념을 보다 정확히 정의하는 것이 필요하다.

<span style='color:green;font-weight:bold'>  Concepts: Basic Level and Prototypes </span><br>
<br>
저자는 *concept* 이란 category (e.g. BIRD)의 정신적 표현(mentral represenatation)이라고 하며, 비슷한 특성을 가진 객체와 사건의 인스턴스가 함께 그룹화된다. 그러나 모든 카테고리 멤버는 동등한 지위를 가지지 않으며, 일부는 다른 멤버들보다 prototypical에 가깝다(e.g. PENGUIS are more atypical BRIDS than ROBINS). 이러한 분류는 문화나 개인의 선호에 의해 제한될 수 있다. 따라서, prototypical, basic-level 카테고리 및 도메인에 대한 카테고리 수는 인지, 문화, 환경적 요소 및 개인적 선호에 의해 제한된다.

<span style='color:green;font-weight:bold'> Limitations of ImageNet </span><br>
<br>
ImageNet의 원래 anntotaion이 '개념이 보편적이고 기본 수준에 있는가'를 확인하기 위한 것은 아니었지만, 이러한 디자인 선택은 많은 언어와 문화에서 일상 생활 시나리오를 추론할 수 있는 다중 모달 시스템을 가능하게 하는 데 중요한 제한 사항으로 나타날 수 있다.
![image](https://user-images.githubusercontent.com/42200027/227844409-5f1c86f2-b7de-41b6-bed2-e527a2e35113.png)
 
<span style='color:green;font-weight:bold'> ImageNet concepts are not universal. </span><br>
<br>
이미지넷은 영어 WordNet에 기반하여 만들어졌으며, 그 결과, 영어권에서는 익숙한 개념이지만 다른 문화권에서는 낯설거나 전혀 알지 못하는 개념도 포함되어 있다. 또한 다른 문화에서의 개념도 포함하지 못할 수 있다. 따라서 이미지넷 개념이 언어별로 얼마나 관련성이 있는지 측정하기 위해, 개별적으로 각 Synset을 Wikipedia 페이지에 매핑하고, 사용 가능한 언어를 추출하였다. 이 결과, 대부분의 Synset은 30개 이하의 언어에서만 존재하며, "universal"한 개념은 매우 적다는 것을 보여주고 있다. 또한 WALS 데이터베이스를 사용하여 언어 가족에도 동일한 논리가 적용되며, 대부분의 언어는 유라시아 대륙에서 나온 것임을 보여준다.

<span style='color:green;font-weight:bold'> ImageNet concepts are overly specifc to English. </span><br>
<br>
이미지넷(ImageNet)은 WordNet의 리프 노드에 속하는 BLENHEIM SϿANIEL 같은 지나치게 구체적인 개념을 포함하고 있으며, 이는 개(DOG)와 같은 기본 수준의 개념보다 더 구체적이다. 또한 이미지에 대한 사람들의 라벨에 사용된 용어의 깊이와 Ordonez 등(2013)의 일부 ImageNet 개념의 WordNet 내 깊이를 비교하여 ImageNet이 보다 미세한 Synsets를 선호하는 것을 확인할 수 있다. 이러한 문제는 영어뿐 아니라 다른 문화권에서 더욱 악화될 수 있다. 일본 악기 '코토'는 영어 사용자들은 '악기'라고 간단히 표현하는 반면, 일본어 사용자들은 더 정확한 표현인 '箏' (코토)를 사용할 것으로 예상된다는 것을 저자들은 발견했다.

<span style='color:green;font-weight:bold'> Sources of Bias </span><br>
<br>
앞서 살펴본 편향의 잠재적 원인들에 대해 살펴본다. 특히, ImageNet, ILSVRC 1K 및 NLVR2와 같은 데이터셋 생성의 각 단계를 따로 검토한다. 이는 1) 개념 선택, 2) 후보 이미지 검색 및 3) 수동 정리 단계를 의미한다. 설계 단계에서 생길 수 있는 편향성 중 첫 번째는 개념의 선택이다. ImageNet은 WordNet으로부터 12개 하위 트리와 총 5,247개의 synset을 선택했다. 그 중에서도 보다 미세한 synset을 선호하여 "밀집된 의미적 계층"을 얻고자 했다. 그 중에서도 ILSVRC 2012-2017 공유 과제를 위해 1,000개의 개념이 임의로 선택되었다. 따라서 1,000개의 개념은 비기본적인 수준으로 편향될 가능성이 있다(예: 147개의 synset은 개 종류다).

저자는 Bias 의 두 번째 원인으로 후보 이미지 검색을 지적한다. 검색 엔진(Flickr와 ILSVRC 1K의 다른 지정되지 않은 엔진, NLVR2의 Google 이미지)에서 얻은 이미지는 성별(Kay 등, 2015)과 인종(Noble, 2018) 등 현실 세계의 분포를 따르지 않는다. 또한, 이들은 사용자의 프로필과 지역에 따라 결과를 사용자 정의한다. ImageNet의 검색어는 다시 영어로 표현되었으며, 일부는(지정되지 않음) 스페인어, 네덜란드어, 이탈리아어 및 중국어(만다린)로 표현되었으며, 이 중 후자만 서구 유럽 언어이다.

저자는 세 번째로, 이미지 필터링에도 추가적인 편향성이 존재할 수 있다고 말한다. 이는 검색 쿼리의 10%만이 적절한 품질을 가지기 때문에 필요하다. ImageNet에서는 Amazon Mechanical Turk를 통해 정리가 이루어졌다. Annotation 작업자들의 언어와 문화에 대한 정보가 없지만, 그들이 전 세계적 다양성을 대표할 수 있다는 근거는 없다. 또한 합의 없이 주석이 되지 않은 부분은 제거되어, 문화적 차이가 사라질 가능성이 있다. (의견이 상이한 것이 그저 다른 기본 수준이나 프로토타입을 나타낼 수도 있음에 유의)

# MaRVL : Dataset Annotation
